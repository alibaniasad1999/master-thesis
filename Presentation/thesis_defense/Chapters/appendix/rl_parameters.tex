\section{RL Algorithm Parameters}

\begin{frame}
  \frametitle{DDPG Parameters}
  \scriptsize
  \begin{tabular}{|l|c||l|c|}
  \hline
  Steps / epoch & 30k & Epochs & 100 \\ \hline
  Buffer size & $10^{6}$ & Discount $\gamma$ & 0.99 \\ \hline
  Polyak $\tau$ & 0.995 & Actor LR & $1\!\times\!10^{-3}$ \\ \hline
  Critic LR & $1\!\times\!10^{-3}$ & Batch size & 1024 \\ \hline
  Start policy steps & 5k & Update start & 1k \\ \hline
  Update interval & 2k & Action noise & 0.1 \\ \hline
  Max episode len & 6k & Device & Cuda \\ \hline
  Net (A/C) & (32,32) & Act fn & ReLU \\ \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{TD3 Parameters}
  \scriptsize
  \begin{tabular}{|l|c||l|c|}
  \hline
  Steps / epoch & 30k & Epochs & 100 \\ \hline
  Buffer size & $10^{6}$ & Discount $\gamma$ & 0.99 \\ \hline
  Polyak $\tau$ & 0.995 & Actor LR & $1\!\times\!10^{-3}$ \\ \hline
  Critic LR & $1\!\times\!10^{-3}$ & Batch size & 1024 \\ \hline
  Start policy steps & 5k & Update start & 1k \\ \hline
  Update interval & 2k & Target noise & 0.2 \\ \hline
  Noise clip & 0.5 & Policy delay & 2 \\ \hline
  Max episode len & 30k & Nets (A/C) & (32,32) \\ \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{SAC Parameters}
  \scriptsize
  \begin{tabular}{|l|c||l|c|}
  \hline
  Steps / epoch & 30k & Epochs & 100 \\ \hline
  Buffer size & $10^{6}$ & Discount $\gamma$ & 0.99 \\ \hline
  Polyak $\tau$ & 0.995 & LR (all) & $1\!\times\!10^{-3}$ \\ \hline
  Alpha init & 0.2 & Batch size & 1024 \\ \hline
  Start steps & 5k & Update start & 1k \\ \hline
  Updates / step & 10 & Update interval & 2k \\ \hline
  Test episodes & 10 & Max len & 30k \\ \hline
  Nets (A/C) & (32,32) & Activation & ReLU \\ \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{PPO Parameters}
  \scriptsize
  \begin{tabular}{|l|c||l|c|}
  \hline
  Steps / epoch & 30k & Epochs & 100 \\ \hline
  Discount $\gamma$ & 0.99 & Clip ratio & 0.2 \\ \hline
  Policy LR & $3\!\times\!10^{-4}$ & Value LR & $1\!\times\!10^{-3}$ \\ \hline
  Policy iters & 80 & Value iters & 80 \\ \hline
  Nets (Actor) & (32,32) & Nets (Critic) & (32,32) \\ \hline
  Activation & ReLU & Batch (mini) & (derived) \\ \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{Training Procedure (Summary)}
  \small
  \begin{enumerate}\setlength{\itemsep}{2pt}
    \item Collect initial random experience (fill replay / buffer).
    \item Loop: act, store $(s,a,r,s',d)$, update (per algo rules).
    \item Target networks: Polyak averaging ($\tau$).
    \item TD3: twin critics + delayed policy + target smoothing.
    \item SAC: entropy term, adaptive temperature (if enabled).
    \item PPO: clipped surrogate objective, on-policy batches.
    \item Stability: normalization, gradient clipping (if needed), fixed seeds.
  \end{enumerate}
\end{frame}

