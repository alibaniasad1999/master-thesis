{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo5KXVOiJubP"
      },
      "source": [
        "# Deep Deterministic Policy Gradient (DDPG)\n",
        "\n",
        "**Author:** [amifunny](https://github.com/amifunny)<br>\n",
        "**Date created:** 2020/06/04<br>\n",
        "**Last modified:** 2020/09/21<br>\n",
        "**Description:** Implementing DDPG algorithm on the Inverted Pendulum Problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asDaHvY-JubZ"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Deep Deterministic Policy Gradient (DDPG)** is a model-free off-policy algorithm for\n",
        "learning continous actions.\n",
        "\n",
        "It combines ideas from DPG (Deterministic Policy Gradient) and DQN (Deep Q-Network).\n",
        "It uses Experience Replay and slow-learning target networks from DQN, and it is based on\n",
        "DPG,\n",
        "which can operate over continuous action spaces.\n",
        "\n",
        "This tutorial closely follow this paper -\n",
        "[Continuous control with deep reinforcement learning](https://arxiv.org/pdf/1509.02971.pdf)\n",
        "\n",
        "## Problem\n",
        "\n",
        "We are trying to solve the classic **Inverted Pendulum** control problem.\n",
        "In this setting, we can take only two actions: swing left or swing right.\n",
        "\n",
        "What make this problem challenging for Q-Learning Algorithms is that actions\n",
        "are **continuous** instead of being **discrete**. That is, instead of using two\n",
        "discrete actions like `-1` or `+1`, we have to select from infinite actions\n",
        "ranging from `-2` to `+2`.\n",
        "\n",
        "## Quick theory\n",
        "\n",
        "Just like the Actor-Critic method, we have two networks:\n",
        "\n",
        "1. Actor - It proposes an action given a state.\n",
        "2. Critic - It predicts if the action is good (positive value) or bad (negative value)\n",
        "given a state and an action.\n",
        "\n",
        "DDPG uses two more techniques not present in the original DQN:\n",
        "\n",
        "**First, it uses two Target networks.**\n",
        "\n",
        "**Why?** Because it add stability to training. In short, we are learning from estimated\n",
        "targets and Target networks are updated slowly, hence keeping our estimated targets\n",
        "stable.\n",
        "\n",
        "Conceptually, this is like saying, \"I have an idea of how to play this well,\n",
        "I'm going to try it out for a bit until I find something better\",\n",
        "as opposed to saying \"I'm going to re-learn how to play this entire game after every\n",
        "move\".\n",
        "See this [StackOverflow answer](https://stackoverflow.com/a/54238556/13475679).\n",
        "\n",
        "**Second, it uses Experience Replay.**\n",
        "\n",
        "We store list of tuples `(state, action, reward, next_state)`, and instead of\n",
        "learning only from recent experience, we learn from sampling all of our experience\n",
        "accumulated so far.\n",
        "\n",
        "Now, let's see how is it implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PMB5KYI2Jubb"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9999, 4)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "## import trajectory data\n",
        "df = pd.read_csv('trajectory.csv')\n",
        "df.head()\n",
        "# df to numpy array\n",
        "data = df.to_numpy()\n",
        "data.shape\n",
        "trajectory = np.delete(data, 2, 1)\n",
        "trajectory = np.delete(trajectory, -1, 1)\n",
        "trajectory.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# three body problem env\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class three_body_env(gym.Env):\n",
        "    def __init__(self, trajectory):\n",
        "        self.trajectory = trajectory\n",
        "        self.state = np.zeros(4)\n",
        "        self.dt = 0.01\n",
        "        self.mu = 0.012277471\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-1, high=1, shape=(4,), dtype=np.float32)\n",
        "        self.position = trajectory[0]\n",
        "        self.steps = 0\n",
        "        self.max_steps = 1000\n",
        "        self.reward_range = (-float('inf'), float('inf'))\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        x = self.position[0]\n",
        "        y = self.position[1]\n",
        "        xdot = self.position[2]\n",
        "        ydot = self.position[3]\n",
        "\n",
        "        a_x = action[0]\n",
        "        a_y = action[1]\n",
        "\n",
        "        r1 = np.sqrt((x+self.mu)**2 + y**2)\n",
        "        r2 = np.sqrt((x-1+self.mu)**2 + y**2)\n",
        "\n",
        "        xddot = 2*ydot + x -(1-self.mu)*((x+self.mu)/(r1**3)) - self.mu*(x-1+self.mu)/(r2**3) + a_x\n",
        "        yddot = -2*xdot + y - (1-self.mu)*(y/(r1**3)) - self.mu*(y)/(r2**3) + a_y\n",
        "\n",
        "        x = x + xdot*self.dt\n",
        "        y = y + ydot*self.dt\n",
        "        \n",
        "        xdot = xdot + xddot*self.dt\n",
        "        ydot = ydot + yddot*self.dt\n",
        "\n",
        "        self.position = np.array([x, y, xdot, ydot])\n",
        "\n",
        "        self.steps += 1\n",
        "\n",
        "        self.position2state()\n",
        "\n",
        "        reward = 1 - np.linalg.norm(self.position - self.trajectory[self.steps], axis=0)\n",
        "        done = self.steps >= self.max_steps\n",
        "        if abs(self.position - self.trajectory[-1]).sum() < 0.005:\n",
        "            done = True\n",
        "            reward = 1000\n",
        "        if self.steps > 1000:\n",
        "            done = True\n",
        "            reward = -1000\n",
        "        if np.linalg.norm(self.state) > 2:\n",
        "            done = True\n",
        "            reward = -1000\n",
        "\n",
        "        return self.state, reward, done, self.position\n",
        "\n",
        "    def position2state(self):\n",
        "        # find nearest point from position to trajectory\n",
        "        distance = np.linalg.norm(self.trajectory - self.position, axis=1)\n",
        "        nearest_idx = np.argmin(distance)\n",
        "        # estate = position - nearest(index)\n",
        "        self.state = self.position - self.trajectory[nearest_idx]\n",
        "    \n",
        "    def reset(self):\n",
        "        self.position = self.trajectory[0]   \n",
        "        self.steps = 0\n",
        "        self.position2state()\n",
        "        return self.state\n",
        "    \n",
        "    def render(self):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    \n",
        "env = three_body_env(trajectory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T2Bp9VQJubd"
      },
      "source": [
        "We use [OpenAIGym](http://gym.openai.com/docs) to create the environment.\n",
        "We will use the `upper_bound` parameter to scale our actions later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ZUOKoRJube",
        "outputId": "2c243960-74c9-49bb-be74-3769f38fb5af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of State Space ->  4\n",
            "Size of Action Space ->  2\n",
            "Max Value of Action ->  1.0\n",
            "Min Value of Action ->  -1.0\n"
          ]
        }
      ],
      "source": [
        "# problem = \"Pendulum-v1\"\n",
        "# env = gym.make(problem)\n",
        "\n",
        "num_states = env.observation_space.shape[0]\n",
        "print(\"Size of State Space ->  {}\".format(num_states))\n",
        "num_actions = env.action_space.shape[0]\n",
        "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
        "\n",
        "upper_bound = env.action_space.high[0]\n",
        "lower_bound = env.action_space.low[0]\n",
        "\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-re1Kp_eJubf"
      },
      "source": [
        "To implement better exploration by the Actor network, we use noisy perturbations,\n",
        "specifically\n",
        "an **Ornstein-Uhlenbeck process** for generating noise, as described in the paper.\n",
        "It samples noise from a correlated normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "laZQCSbrJubf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class OUActionNoise:\n",
        "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
        "        self.theta = theta\n",
        "        self.mean = mean\n",
        "        self.std_dev = std_deviation\n",
        "        self.dt = dt\n",
        "        self.x_initial = x_initial\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self):\n",
        "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
        "        x = (\n",
        "            self.x_prev\n",
        "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
        "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
        "        )\n",
        "        # Store x into x_prev\n",
        "        # Makes next noise dependent on current one\n",
        "        self.x_prev = x\n",
        "        return x\n",
        "\n",
        "    def reset(self):\n",
        "        if self.x_initial is not None:\n",
        "            self.x_prev = self.x_initial\n",
        "        else:\n",
        "            self.x_prev = np.zeros_like(self.mean)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCv2yg3CJubg"
      },
      "source": [
        "The `Buffer` class implements Experience Replay.\n",
        "\n",
        "---\n",
        "![Algorithm](https://i.imgur.com/mS6iGyJ.jpg)\n",
        "---\n",
        "\n",
        "\n",
        "**Critic loss** - Mean Squared Error of `y - Q(s, a)`\n",
        "where `y` is the expected return as seen by the Target network,\n",
        "and `Q(s, a)` is action value predicted by the Critic network. `y` is a moving target\n",
        "that the critic model tries to achieve; we make this target\n",
        "stable by updating the Target model slowly.\n",
        "\n",
        "**Actor loss** - This is computed using the mean of the value given by the Critic network\n",
        "for the actions taken by the Actor network. We seek to maximize this quantity.\n",
        "\n",
        "Hence we update the Actor network so that it produces actions that get\n",
        "the maximum predicted value as seen by the Critic, for a given state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KuZOHV5pJubh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Buffer:\n",
        "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
        "        # Number of \"experiences\" to store at max\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        # Num of tuples to train on.\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Its tells us num of times record() was called.\n",
        "        self.buffer_counter = 0\n",
        "\n",
        "        # Instead of list of tuples as the exp.replay concept go\n",
        "        # We use different np.arrays for each tuple element\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "\n",
        "    # Takes (s,a,r,s') observation tuple as input\n",
        "    def record(self, obs_tuple):\n",
        "        # Set index to zero if buffer_capacity is exceeded,\n",
        "        # replacing old records\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "\n",
        "        self.state_buffer[index] = obs_tuple[0]\n",
        "        self.action_buffer[index] = obs_tuple[1][0]\n",
        "        self.reward_buffer[index] = obs_tuple[2]\n",
        "        self.next_state_buffer[index] = obs_tuple[3]\n",
        "\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "    # Eager execution is turned on by default in TensorFlow 2. Decorating with tf.function allows\n",
        "    # TensorFlow to build a static graph out of the logic and computations in our function.\n",
        "    # This provides a large speed up for blocks of code that contain many small TensorFlow operations such as this one.\n",
        "    @tf.function\n",
        "    def update(\n",
        "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
        "    ):\n",
        "        # Training and updating Actor & Critic networks.\n",
        "        # See Pseudo Code.\n",
        "        with tf.GradientTape() as tape:\n",
        "            target_actions = target_actor(next_state_batch, training=True)\n",
        "            y = reward_batch + gamma * target_critic(\n",
        "                [next_state_batch, target_actions], training=True\n",
        "            )\n",
        "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
        "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
        "\n",
        "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
        "        critic_optimizer.apply_gradients(\n",
        "            zip(critic_grad, critic_model.trainable_variables)\n",
        "        )\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions = actor_model(state_batch, training=True)\n",
        "            critic_value = critic_model([state_batch, actions], training=True)\n",
        "            # Used `-value` as we want to maximize the value given\n",
        "            # by the critic for our actions\n",
        "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
        "\n",
        "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
        "        actor_optimizer.apply_gradients(\n",
        "            zip(actor_grad, actor_model.trainable_variables)\n",
        "        )\n",
        "\n",
        "    # We compute the loss and update parameters\n",
        "    def learn(self):\n",
        "        # Get sampling range\n",
        "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
        "        # Randomly sample indices\n",
        "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
        "\n",
        "        # Convert to tensors\n",
        "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
        "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
        "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
        "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
        "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
        "\n",
        "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
        "\n",
        "\n",
        "# This update target parameters slowly\n",
        "# Based on rate `tau`, which is much less than one.\n",
        "@tf.function\n",
        "def update_target(target_weights, weights, tau):\n",
        "    for (a, b) in zip(target_weights, weights):\n",
        "        a.assign(b * tau + a * (1 - tau))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21w090e3Jubi"
      },
      "source": [
        "Here we define the Actor and Critic networks. These are basic Dense models\n",
        "with `ReLU` activation.\n",
        "\n",
        "Note: We need the initialization for last layer of the Actor to be between\n",
        "`-0.003` and `0.003` as this prevents us from getting `1` or `-1` output values in\n",
        "the initial stages, which would squash our gradients to zero,\n",
        "as we use the `tanh` activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sb0H13J1Jubi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_actor():\n",
        "    # Initialize weights between -3e-3 and 3-e3\n",
        "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
        "\n",
        "    inputs = layers.Input(shape=(num_states,))\n",
        "    out = layers.Dense(256, activation=\"relu\")(inputs)\n",
        "    out = layers.Dense(256, activation=\"relu\")(out)\n",
        "    outputs = layers.Dense(2, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
        "\n",
        "    # Our upper bound is 2.0 for Pendulum.\n",
        "    outputs = outputs * upper_bound\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model = tf.keras.models.load_model('model.h5')\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_critic():\n",
        "    # State as input\n",
        "    state_input = layers.Input(shape=(num_states))\n",
        "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
        "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
        "\n",
        "    # Action as input\n",
        "    action_input = layers.Input(shape=(num_actions))\n",
        "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
        "\n",
        "    # Both are passed through seperate layer before concatenating\n",
        "    concat = layers.Concatenate()([state_out, action_out])\n",
        "\n",
        "    out = layers.Dense(256, activation=\"relu\")(concat)\n",
        "    out = layers.Dense(256, activation=\"relu\")(out)\n",
        "    outputs = layers.Dense(1)(out)\n",
        "\n",
        "    # Outputs single value for give state-action\n",
        "    model = tf.keras.Model([state_input, action_input], outputs)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTv828xuJubj"
      },
      "source": [
        "`policy()` returns an action sampled from our Actor network plus some noise for\n",
        "exploration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4LYuCvV9Jubk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def policy(state, noise_object):\n",
        "    sampled_actions = tf.squeeze(actor_mode(state.reshape(1,4)))\n",
        "    noise = noise_object()\n",
        "    # Adding noise to action\n",
        "    sampled_actions = sampled_actions.numpy() + noise\n",
        "\n",
        "    # We make sure action is within bounds\n",
        "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
        "\n",
        "    return [np.squeeze(legal_action)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODzKYHuDJubk"
      },
      "source": [
        "## Training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PZsr1Jv_Jubl"
      },
      "outputs": [],
      "source": [
        "std_dev = 0.2\n",
        "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
        "\n",
        "actor_model = get_actor()\n",
        "critic_model = get_critic()\n",
        "\n",
        "target_actor = get_actor()\n",
        "target_critic = get_critic()\n",
        "\n",
        "# Making the weights equal initially\n",
        "target_actor.set_weights(actor_model.get_weights())\n",
        "target_critic.set_weights(critic_model.get_weights())\n",
        "\n",
        "# Learning rate for actor-critic models\n",
        "critic_lr = 0.002\n",
        "actor_lr = 0.001\n",
        "\n",
        "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
        "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
        "\n",
        "total_episodes = 100\n",
        "# Discount factor for future rewards\n",
        "gamma = 0.99\n",
        "# Used to update target networks\n",
        "tau = 0.005\n",
        "\n",
        "buffer = Buffer(50000, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iITRwMMhJubm"
      },
      "source": [
        "Now we implement our main training loop, and iterate over episodes.\n",
        "We sample actions using `policy()` and train with `learn()` at each time step,\n",
        "along with updating the Target networks at a rate `tau`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NCdipSOsJubn"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'actor_mode' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Uncomment this to see the Actor in action\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# But not in a python notebook.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# env.render()\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     tf_prev_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(prev_state), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_prev_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mou_noise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Recieve state and reward from environment.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
            "Cell \u001b[0;32mIn[26], line 2\u001b[0m, in \u001b[0;36mpolicy\u001b[0;34m(state, noise_object)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolicy\u001b[39m(state, noise_object):\n\u001b[0;32m----> 2\u001b[0m     sampled_actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mactor_mode\u001b[49m(state\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m)))\n\u001b[1;32m      3\u001b[0m     noise \u001b[38;5;241m=\u001b[39m noise_object()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Adding noise to action\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'actor_mode' is not defined"
          ]
        }
      ],
      "source": [
        "# To store reward history of each episode\n",
        "ep_reward_list = []\n",
        "# To store average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "\n",
        "# Takes about 4 min to train\n",
        "for ep in range(total_episodes):\n",
        "\n",
        "    prev_state= env.reset()\n",
        "    episodic_reward = 0\n",
        "\n",
        "    while True:\n",
        "        # Uncomment this to see the Actor in action\n",
        "        # But not in a python notebook.\n",
        "        # env.render()\n",
        "\n",
        "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
        "\n",
        "        action = policy(tf_prev_state, ou_noise)\n",
        "        # Recieve state and reward from environment.\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        buffer.record((prev_state, action, reward, state))\n",
        "        episodic_reward += reward\n",
        "\n",
        "        buffer.learn()\n",
        "        update_target(target_actor.variables, actor_model.variables, tau)\n",
        "        update_target(target_critic.variables, critic_model.variables, tau)\n",
        "\n",
        "        # End this episode when `done` is True\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        prev_state = state\n",
        "\n",
        "    ep_reward_list.append(episodic_reward)\n",
        "\n",
        "    # Mean of last 40 episodes\n",
        "    avg_reward = np.mean(ep_reward_list[-40:])\n",
        "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
        "    avg_reward_list.append(avg_reward)\n",
        "\n",
        "# Plotting graph\n",
        "# Episodes versus Avg. Rewards\n",
        "plt.plot(avg_reward_list)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## run simulation\n",
        "prev_state= env.reset()\n",
        "state_array = []\n",
        "action_array = []\n",
        "while True:\n",
        "    # env.render()\n",
        "    tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
        "    action = tf.squeeze(actor_model(prev_state.reshape(1, 4)))\n",
        "    state, reward, done, info = env.step(action)\n",
        "    state_array.append(state)\n",
        "    action_array.append(action)\n",
        "    if done:\n",
        "        break\n",
        "    prev_state = state\n",
        "\n",
        "state_array = np.array(state_array)\n",
        "action_array = np.array(action_array)\n",
        "plt.plot(trajectory[:,0], trajectory[:,1])\n",
        "plt.plot(state_array[:,0], state_array[:,1])\n",
        "# plt.plot(state_array[:,0])\n",
        "plt.show()\n",
        "\n",
        "# plot action\n",
        "# plt.plot(action_array)\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26J7q3t8Jubo"
      },
      "source": [
        "If training proceeds correctly, the average episodic reward will increase with time.\n",
        "\n",
        "Feel free to try different learning rates, `tau` values, and architectures for the\n",
        "Actor and Critic networks.\n",
        "\n",
        "The Inverted Pendulum problem has low complexity, but DDPG work great on many other\n",
        "problems.\n",
        "\n",
        "Another great environment to try this on is `LunarLandingContinuous-v2`, but it will take\n",
        "more episodes to obtain good results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj9cDTsmJubp"
      },
      "outputs": [],
      "source": [
        "# Save the weights\n",
        "actor_model.save_weights(\"pendulum_actor.h5\")\n",
        "critic_model.save_weights(\"pendulum_critic.h5\")\n",
        "\n",
        "target_actor.save_weights(\"pendulum_target_actor.h5\")\n",
        "target_critic.save_weights(\"pendulum_target_critic.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddpg_pendulum",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
