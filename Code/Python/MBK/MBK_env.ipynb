{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MNdAvxAg2nbq"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Define the custom Gym environment for the mass-spring-damper system\n",
    "class MassSpringDamperEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(MassSpringDamperEnv, self).__init__()\n",
    "\n",
    "        # System parameters\n",
    "        self.m = 1.0  # Mass (kg)\n",
    "        self.k = 1.0  # Spring constant (N/m)\n",
    "        self.c = 0.1  # Damping coefficient (N*s/m)\n",
    "\n",
    "        # Simulation parameters\n",
    "        self.dt = 0.01  # Time step (s)\n",
    "        self.max_steps = 1000  # Maximum simulation steps\n",
    "        self.current_step = 0\n",
    "\n",
    "        # State and action spaces\n",
    "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,))\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(2,))\n",
    "\n",
    "        # Initial state\n",
    "        self.state = None\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to an initial state\n",
    "        self.state = np.array([10.0, 0.0])  # Initial position and velocity\n",
    "        self.current_step = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply control action and simulate one time step using Euler integration\n",
    "        force = action[0]\n",
    "        position, velocity = self.state\n",
    "\n",
    "        acceleration = (force - self.c * velocity - self.k * position) / self.m\n",
    "        velocity += acceleration * self.dt\n",
    "        position += velocity * self.dt\n",
    "\n",
    "        self.state = np.array([position, velocity])\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Calculate the reward (e.g., minimize position error)\n",
    "        reward = -abs(position)  # Negative position as the reward (minimize position error)\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self.current_step >= self.max_steps\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Create the custom mass-spring-damper environment\n",
    "env = MassSpringDamperEnv()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
