{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 19:08:24.838041: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  A_input: [None, 3]\n",
      "[TL] Dense  A_l1: 64 relu\n",
      "[TL] Dense  A_l2: 64 relu\n",
      "[TL] Dense  A_a: 1 tanh\n",
      "[TL] Lambda  lambda_1: func: <function DDPG.__init__.<locals>.get_actor.<locals>.<lambda> at 0x13d8a6840>, len_weights: 0\n",
      "[TL] Input  C_s_input: [None, 3]\n",
      "[TL] Input  C_a_input: [None, 1]\n",
      "[TL] Concat concat_1: concat_dim: 1\n",
      "[TL] Dense  C_l1: 64 relu\n",
      "[TL] Dense  C_l2: 64 relu\n",
      "[TL] Dense  C_out: 1 No Activation\n",
      "[TL] Input  A_input: [None, 3]\n",
      "[TL] Dense  A_l1: 64 relu\n",
      "[TL] Dense  A_l2: 64 relu\n",
      "[TL] Dense  A_a: 1 tanh\n",
      "[TL] Lambda  lambda_2: func: <function DDPG.__init__.<locals>.get_actor.<locals>.<lambda> at 0x13d8a76a0>, len_weights: 0\n",
      "[TL] Input  C_s_input: [None, 3]\n",
      "[TL] Input  C_a_input: [None, 1]\n",
      "[TL] Concat concat_2: concat_dim: 1\n",
      "[TL] Dense  C_l1: 64 relu\n",
      "[TL] Dense  C_l2: 64 relu\n",
      "[TL] Dense  C_out: 1 No Activation\n",
      "Training  | Episode: 1/100  | Episode Reward: -1481.4299  | Running Time: 0.4036\n",
      "Training  | Episode: 2/100  | Episode Reward: -1315.8514  | Running Time: 0.7905\n",
      "Training  | Episode: 3/100  | Episode Reward: -1410.4152  | Running Time: 1.1681\n",
      "Training  | Episode: 4/100  | Episode Reward: -1515.1455  | Running Time: 1.7593\n",
      "Training  | Episode: 5/100  | Episode Reward: -1497.6507  | Running Time: 2.3821\n",
      "Training  | Episode: 6/100  | Episode Reward: -1471.4103  | Running Time: 3.2496\n",
      "Training  | Episode: 7/100  | Episode Reward: -1489.9344  | Running Time: 4.2997\n",
      "Training  | Episode: 8/100  | Episode Reward: -1498.4706  | Running Time: 4.9208\n",
      "Training  | Episode: 9/100  | Episode Reward: -1472.0217  | Running Time: 5.4926\n",
      "Training  | Episode: 10/100  | Episode Reward: -1405.5848  | Running Time: 6.0881\n",
      "Training  | Episode: 11/100  | Episode Reward: -1429.0884  | Running Time: 7.0871\n",
      "Training  | Episode: 12/100  | Episode Reward: -1301.5276  | Running Time: 7.7817\n",
      "Training  | Episode: 13/100  | Episode Reward: -1432.2768  | Running Time: 8.6078\n",
      "Training  | Episode: 14/100  | Episode Reward: -1386.2603  | Running Time: 9.5191\n",
      "Training  | Episode: 15/100  | Episode Reward: -1487.2588  | Running Time: 10.3833\n",
      "Training  | Episode: 16/100  | Episode Reward: -1390.8209  | Running Time: 11.0169\n",
      "Training  | Episode: 17/100  | Episode Reward: -1425.4428  | Running Time: 13.0116\n",
      "Training  | Episode: 18/100  | Episode Reward: -1506.7935  | Running Time: 14.3400\n",
      "Training  | Episode: 19/100  | Episode Reward: -1466.7561  | Running Time: 15.1454\n",
      "Training  | Episode: 20/100  | Episode Reward: -1369.1885  | Running Time: 15.8247\n",
      "Training  | Episode: 21/100  | Episode Reward: -1434.5124  | Running Time: 16.4431\n",
      "Training  | Episode: 22/100  | Episode Reward: -1387.3759  | Running Time: 17.2127\n",
      "Training  | Episode: 23/100  | Episode Reward: -1421.2583  | Running Time: 17.7454\n",
      "Training  | Episode: 24/100  | Episode Reward: -1417.3104  | Running Time: 18.3856\n",
      "Training  | Episode: 25/100  | Episode Reward: -1473.2068  | Running Time: 19.0573\n",
      "Training  | Episode: 26/100  | Episode Reward: -1373.5423  | Running Time: 19.9310\n",
      "Training  | Episode: 27/100  | Episode Reward: -1390.0428  | Running Time: 20.5784\n",
      "Training  | Episode: 28/100  | Episode Reward: -1393.1902  | Running Time: 21.1195\n",
      "Training  | Episode: 29/100  | Episode Reward: -1316.7203  | Running Time: 21.7040\n",
      "Training  | Episode: 30/100  | Episode Reward: -1400.2869  | Running Time: 22.3287\n",
      "Training  | Episode: 31/100  | Episode Reward: -1410.1511  | Running Time: 23.0829\n",
      "Training  | Episode: 32/100  | Episode Reward: -1418.6646  | Running Time: 23.6635\n",
      "Training  | Episode: 33/100  | Episode Reward: -1357.1535  | Running Time: 24.3961\n",
      "Training  | Episode: 34/100  | Episode Reward: -1442.2481  | Running Time: 25.0319\n",
      "Training  | Episode: 35/100  | Episode Reward: -1419.2926  | Running Time: 25.5459\n",
      "Training  | Episode: 36/100  | Episode Reward: -1386.1835  | Running Time: 26.2735\n",
      "Training  | Episode: 37/100  | Episode Reward: -1320.5120  | Running Time: 26.9200\n",
      "Training  | Episode: 38/100  | Episode Reward: -1411.1520  | Running Time: 27.6063\n",
      "Training  | Episode: 39/100  | Episode Reward: -1429.5105  | Running Time: 28.2470\n",
      "Training  | Episode: 40/100  | Episode Reward: -1426.8278  | Running Time: 28.9405\n",
      "Training  | Episode: 41/100  | Episode Reward: -1393.0602  | Running Time: 29.5317\n",
      "Training  | Episode: 42/100  | Episode Reward: -1488.2722  | Running Time: 30.0893\n",
      "Training  | Episode: 43/100  | Episode Reward: -1243.4704  | Running Time: 30.7130\n",
      "Training  | Episode: 44/100  | Episode Reward: -1449.0997  | Running Time: 31.3098\n",
      "Training  | Episode: 45/100  | Episode Reward: -1394.6586  | Running Time: 32.0477\n",
      "Training  | Episode: 46/100  | Episode Reward: -1425.4840  | Running Time: 32.6825\n",
      "Training  | Episode: 47/100  | Episode Reward: -1448.7002  | Running Time: 33.3037\n",
      "Training  | Episode: 48/100  | Episode Reward: -1356.8524  | Running Time: 33.9360\n",
      "Training  | Episode: 49/100  | Episode Reward: -1362.1567  | Running Time: 34.5234\n",
      "Training  | Episode: 50/100  | Episode Reward: -1463.9122  | Running Time: 35.0706\n",
      "Training  | Episode: 51/100  | Episode Reward: -1219.3899  | Running Time: 55.0513\n",
      "Training  | Episode: 52/100  | Episode Reward: -1310.2019  | Running Time: 80.6276\n",
      "Training  | Episode: 53/100  | Episode Reward: -1758.7910  | Running Time: 104.3075\n",
      "Training  | Episode: 54/100  | Episode Reward: -1603.7700  | Running Time: 136.9767\n",
      "Training  | Episode: 55/100  | Episode Reward: -1466.9304  | Running Time: 164.9783\n",
      "Training  | Episode: 56/100  | Episode Reward: -1341.9182  | Running Time: 187.3239\n",
      "Training  | Episode: 57/100  | Episode Reward: -1224.3279  | Running Time: 208.0467\n",
      "Training  | Episode: 58/100  | Episode Reward: -1026.7119  | Running Time: 228.8334\n",
      "Training  | Episode: 59/100  | Episode Reward: -1021.5003  | Running Time: 247.8506\n",
      "Training  | Episode: 60/100  | Episode Reward: -886.8906  | Running Time: 265.5268\n",
      "Training  | Episode: 61/100  | Episode Reward: -911.6156  | Running Time: 284.3546\n",
      "Training  | Episode: 62/100  | Episode Reward: -384.8701  | Running Time: 305.8019\n",
      "Training  | Episode: 63/100  | Episode Reward: -263.4014  | Running Time: 329.0683\n",
      "Training  | Episode: 64/100  | Episode Reward: -134.1708  | Running Time: 345.1472\n",
      "Training  | Episode: 65/100  | Episode Reward: -131.5637  | Running Time: 367.4060\n",
      "Training  | Episode: 66/100  | Episode Reward: -126.6308  | Running Time: 392.8199\n",
      "Training  | Episode: 67/100  | Episode Reward: -133.6999  | Running Time: 420.2013\n",
      "Training  | Episode: 68/100  | Episode Reward: -297.3634  | Running Time: 442.5673\n",
      "Training  | Episode: 69/100  | Episode Reward: -270.3774  | Running Time: 465.2938\n",
      "Training  | Episode: 70/100  | Episode Reward: -127.2477  | Running Time: 482.9100\n",
      "Training  | Episode: 71/100  | Episode Reward: -0.8639  | Running Time: 502.2519\n",
      "Training  | Episode: 72/100  | Episode Reward: -238.9842  | Running Time: 523.5525\n",
      "Training  | Episode: 73/100  | Episode Reward: -265.0289  | Running Time: 541.7634\n",
      "Training  | Episode: 74/100  | Episode Reward: -243.3807  | Running Time: 561.0156\n",
      "Training  | Episode: 75/100  | Episode Reward: -250.1991  | Running Time: 579.1844\n",
      "Training  | Episode: 76/100  | Episode Reward: -386.1875  | Running Time: 603.1393\n",
      "Training  | Episode: 77/100  | Episode Reward: -245.9305  | Running Time: 622.3302\n",
      "Training  | Episode: 78/100  | Episode Reward: -272.9277  | Running Time: 669.7346\n",
      "Training  | Episode: 79/100  | Episode Reward: -135.0280  | Running Time: 704.8914\n",
      "Training  | Episode: 80/100  | Episode Reward: -384.8730  | Running Time: 742.2966\n",
      "Training  | Episode: 81/100  | Episode Reward: -131.0398  | Running Time: 784.5082\n",
      "Training  | Episode: 82/100  | Episode Reward: -128.2763  | Running Time: 819.2218\n",
      "Training  | Episode: 83/100  | Episode Reward: -134.4260  | Running Time: 850.8595\n",
      "Training  | Episode: 84/100  | Episode Reward: -299.4569  | Running Time: 885.6832\n",
      "Training  | Episode: 85/100  | Episode Reward: -2.6011  | Running Time: 919.0060\n",
      "Training  | Episode: 86/100  | Episode Reward: -253.2185  | Running Time: 944.5130\n",
      "Training  | Episode: 87/100  | Episode Reward: -128.1492  | Running Time: 968.9014\n",
      "Training  | Episode: 88/100  | Episode Reward: -254.0655  | Running Time: 1004.8156\n",
      "Training  | Episode: 89/100  | Episode Reward: -1.5256  | Running Time: 1023.3697\n",
      "Training  | Episode: 90/100  | Episode Reward: -132.1352  | Running Time: 1042.8939\n",
      "Training  | Episode: 91/100  | Episode Reward: -244.7492  | Running Time: 1062.7035\n",
      "Training  | Episode: 92/100  | Episode Reward: -1.5701  | Running Time: 1076.3902\n",
      "Training  | Episode: 93/100  | Episode Reward: -1.5976  | Running Time: 1087.7075\n",
      "Training  | Episode: 94/100  | Episode Reward: -253.0046  | Running Time: 1098.9723\n",
      "Training  | Episode: 95/100  | Episode Reward: -260.1909  | Running Time: 1110.1959\n",
      "Training  | Episode: 96/100  | Episode Reward: -132.1354  | Running Time: 1121.5270\n",
      "Training  | Episode: 97/100  | Episode Reward: -130.4855  | Running Time: 1133.0810\n",
      "Training  | Episode: 98/100  | Episode Reward: -251.2273  | Running Time: 1144.4335\n",
      "Training  | Episode: 99/100  | Episode Reward: -135.5186  | Running Time: 1156.0916\n",
      "Training  | Episode: 100/100  | Episode Reward: -124.5801  | Running Time: 1167.5738\n",
      "[TL] [*] Saving TL weights into model/DDPG_Pendulum-v1/actor.hdf5\n",
      "[TL] [*] Saved\n",
      "[TL] [*] Saving TL weights into model/DDPG_Pendulum-v1/actor_target.hdf5\n",
      "[TL] [*] Saved\n",
      "[TL] [*] Saving TL weights into model/DDPG_Pendulum-v1/critic.hdf5\n",
      "[TL] [*] Saved\n",
      "[TL] [*] Saving TL weights into model/DDPG_Pendulum-v1/critic_target.hdf5\n",
      "[TL] [*] Saved\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 290\u001b[0m\n\u001b[1;32m    286\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ALG_NAME, ENV_ID])))\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TEST_EPISODES):\n\u001b[1;32m    292\u001b[0m         state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "Cell \u001b[0;32mIn[1], line 230\u001b[0m, in \u001b[0;36mDDPG.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03mload trained weights\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m:return: None\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ALG_NAME, ENV_ID]))\n\u001b[0;32m--> 230\u001b[0m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_hdf5_to_weights_in_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactor.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m tl\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mload_hdf5_to_weights_in_order(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_target.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target)\n\u001b[1;32m    232\u001b[0m tl\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mload_hdf5_to_weights_in_order(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritic.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic)\n",
      "File \u001b[0;32m~/Documents/BAI/Master/master-thesis/.env/lib/python3.11/site-packages/tensorlayer/files/utils.py:2730\u001b[0m, in \u001b[0;36mload_hdf5_to_weights_in_order\u001b[0;34m(filepath, network)\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(network\u001b[38;5;241m.\u001b[39mall_layers) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(layer_names):\n\u001b[1;32m   2724\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   2725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of weights mismatch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load a saved file with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(layer_names)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m layers into a model with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   2727\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(network\u001b[38;5;241m.\u001b[39mall_layers)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2728\u001b[0m     )\n\u001b[0;32m-> 2730\u001b[0m \u001b[43m_load_weights_from_hdf5_group_in_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2732\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   2733\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[*] Load \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m SUCCESS!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filepath)\n",
      "File \u001b[0;32m~/Documents/BAI/Master/master-thesis/.env/lib/python3.11/site-packages/tensorlayer/files/utils.py:2605\u001b[0m, in \u001b[0;36m_load_weights_from_hdf5_group_in_order\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_weights_from_hdf5_group_in_order\u001b[39m(f, layers):\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m    Load layer weights from a hdf5 group sequentially.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \n\u001b[1;32m   2604\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m     layer_names \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layer_names):\n\u001b[1;32m   2608\u001b[0m         g \u001b[38;5;241m=\u001b[39m f[name]\n",
      "File \u001b[0;32m~/Documents/BAI/Master/master-thesis/.env/lib/python3.11/site-packages/tensorlayer/files/utils.py:2605\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_weights_from_hdf5_group_in_order\u001b[39m(f, layers):\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m    Load layer weights from a hdf5 group sequentially.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \n\u001b[1;32m   2604\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m     layer_names \u001b[38;5;241m=\u001b[39m [\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layer_names):\n\u001b[1;32m   2608\u001b[0m         g \u001b[38;5;241m=\u001b[39m f[name]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJ2ElEQVR4nO3deXxU1d3H8c/MJJmskwTIAiSBsAiEfRODK0qJLbRSWx9xK7gWHmxlqQLVQrVFHrW2xRWtrdCqFaStbQHByKK1RIFA2MMiS0JCFsgyIXtm7vNHyNSULYEkN5l836/XvHDmnpn7u0eS+XLuuedaDMMwEBEREfFiVrMLEBEREWluCjwiIiLi9RR4RERExOsp8IiIiIjXU+ARERERr6fAIyIiIl5PgUdERES8ngKPiIiIeD0fswtoDdxuN9nZ2YSEhGCxWMwuR0RERBrAMAxKSkro0qULVuvFx3AUeIDs7GxiY2PNLkNEREQuQ2ZmJjExMRdto8ADhISEALUd5nA4TK5GREREGsLpdBIbG+v5Hr8YBR7wnMZyOBwKPCIiIm1MQ6ajaNKyiIiIeD0FHhEREfF6CjwiIiLi9RR4RERExOsp8IiIiIjXU+ARERERr6fAIyIiIl5PgUdERES8ngKPiIiIeD0FHhEREfF6CjwiIiLi9RR4RERExOvp5qEiIiLSbDJOl/GPnVkUlVXz1IQE0+pQ4BEREfFynx3MJ9dZwa0Dognx973szzlTWUNhaRUx4QEXvUN5XkkFq3ed5O9p2aRlFgHgZ7Pyo5t7Exp4+fu/Eqad0jp27BgPPvgg8fHxBAQE0LNnTxYsWEBVVVW9drt27eL666/H39+f2NhYnn/++XM+64MPPqBv3774+/szcOBA1qxZ01KHISIi0qqt3ZPD5Le38PjKXVy9cD0/+WAn244VYBhGg95fUe1ize6TTHsnleG/SOb65zdy62//xZuffUVeSYWnXXZROUv/fZRJb6ZwzbPrefqf+0jLLMJqget6deKX3x2An495M2lMG+FJT0/H7Xbzxhtv0KtXL/bs2cPDDz9MaWkpv/rVrwBwOp2MGzeOsWPHsmTJEnbv3s0DDzxAWFgYjzzyCACbN2/mrrvuYtGiRUyYMIH33nuPiRMnsn37dgYMGGDW4YmIiJhuR0YhM5bvwDCgQ5AfBaVVrEw9wcrUE/SMCGLSyDhuH9aVjsH2eu9zuQ1SvjrNX7efYN3eHEqrXJ5tVgscyC3h2TXpPLf2ANf16kRReTU7z47k1BkaF8Z3Bndh/KDORIb4t8ThXpTFaGjEawEvvPACr7/+OkeOHAHg9ddf58knnyQnJwc/Pz8A5s6dy4cffkh6ejoAd955J6WlpaxatcrzOddccw1DhgxhyZIlDdqv0+kkNDSU4uJiHA5HEx+ViIhIy8s4XcZ3X/s3p0uruLlvJG/eN5ydJ4pYvjWTf+48SXl1bYjxtVn4RkIUd46Mo2tYAH/bcYK/bc8iu/g/ozddwwKYMLgz3x7UhdgOgazedZKVqZlszyjytLFYYES3cJL6R5PUP5rYDoHNfoyN+f5uVXN4iouL6dChg+d5SkoKN9xwgyfsACQlJfHcc89RWFhIeHg4KSkpzJo1q97nJCUl8eGHH7ZU2SIiIq1KUVkVU5Zu4XRpFf27OHj5rqH42KwM79aB4d068LMJCfxz50mWb81g54li1uzOYc3unHqf4fD34TtDujBxSFeGxYVjtf5nzs7do+K4e1QcX+WfYd3eHEIDfPlGQlSrGMm5kFYTeA4fPszLL7/sOZ0FkJOTQ3x8fL12UVFRnm3h4eHk5OR4Xvt6m5yc+v/jvq6yspLKykrPc6fT2RSHICIiYrrKGheP/CmVI/mldAn15w9TRhJkr/91H+Lv6wkt+7KdrNiWyV+3n+BMZQ03XhXB94fHcku/SPx9bRfdV8+IYP73pl7NeThNpskDz9y5c3nuuecu2mb//v307dvX8zwrK4tbb72VO+64g4cffripSzrHokWLePrpp5t9PyIiIi3JMAx+9uEethwtIMTuw9v3X02U4+KjLgldHPz8O/356bf6Ue1ynxOOvEWTH9Xs2bOZMmXKRdv06NHD89/Z2dmMGTOG0aNH8+abb9ZrFx0dTW5ubr3X6p5HR0dftE3d9vOZN29evdNgTqeT2NjYi9YsIiLS2v15SyYrtp3AaoHX7h1Gn+iQBr/Xz8dq6lVUza3JA09ERAQRERENapuVlcWYMWMYPnw4b7/9NlZr/Y5OTEzkySefpLq6Gl/f2uv2k5OT6dOnD+Hh4Z4269evZ8aMGZ73JScnk5iYeMH92u127Hb7BbeLiIi0NWmZRfz8H3sBeDypL9f3bth3cXthWpTLysripptuIi4ujl/96lfk5+eTk5NTb+7N3XffjZ+fHw8++CB79+5l+fLlLF68uN7ozGOPPcbatWt58cUXSU9P5+c//znbtm3j0UcfNeOwREREWtzpM5X87zupVLncJPWPYuqNPS79pnbGtBN1ycnJHD58mMOHDxMTE1NvW92V8qGhoXz88cdMnz6d4cOH06lTJ+bPn+9Zgwdg9OjRvPfeezz11FP89Kc/pXfv3nz44Ydag0dERNqFGpebH7+/g+ziCnp0CuJXdwy+6CrI7VWrWofHLFqHR0REWrvTZyp5MfkgyftyCQvwpXNYAJ0d/hSVV7Fuby6Bfjb+Pv1aekc1fN5OW9dm1+ERERGR+mpcbt754ji/Tj6Is6IGgPySSg7lnanX7vnvD2pXYaexFHhERERaqZSvTrPgH3s4mFsbbhI6O3j81j74Wq1kF5eTU1zByeIKBseEMmFQF5Orbd0UeERERFqhfx8+xb2//xLDgPBAX36S1IdJI+OwWTU/53Io8IiIiLQyzopqHv9gJ4YB3xoYzbPfHUhYoN+l3ygXpMAjIiLSyvxy1T6yiyvo1jGQF74/2GtXP25J3rukooiISBu0fn8uK7adwGKBX92hsNNUFHhERERaicLSKub+dTcAD10Xz8juHUyuyHso8IiIiLQSC/6xl/ySSnpFBjN7XB+zy/EqGicTERFpYYZh8K9Dp8gqKqe0soayKhcniyv4x85sbFYLL94xGH9fm9llehUFHhERkRZUUe3iJx/sZNWuk+fd/r839WRwbFjLFtUOKPCIiIi0kLySCh75YyppmUX4WC3c1CeCYLsPgXYfgvxs9IoM5nvDYi79QdJoCjwiIiItYP9JJw8t20ZWUTmhAb4suXc4iT07ml1Wu6HAIyIi0gzcboOsonKOnCol/aSTl9YforTKRXynIP4wZSTxnYLMLrFdUeARERFpQkfyz/D4yl3sziqmqsZdb9s1PTqw5N7hWjXZBAo8IiIiTcQwDOb+ZTepxwsB8LNZ6dYxkB4RQQyLC+f+a+Px89GKMGZQ4BEREWkia3bnsOVYAf6+VlZOHU2/zg7d7LOVUOARERFpAhXVLp5dsx+AH97QkwFdQ02uSL5O42oiIiJN4PefHyWrqJzOof5MvbGn2eXIf1HgERERuUK5zgpe3XgYgDm39iXAT6sktzYKPCIiIlfohXUHKKtyMTQujNuGdDG7HDkPBR4REZErsOtEEStTTwAwf0ICFosmKbdGmrQsIiLSQHnOCpalHONkcQXFZdUUlVdz9FQpAN8d2pWhceEmVygXosAjIiLSAIWlVUz63RccyS89Z1uIvw9P3NrHhKqkoRR4RERELqG8ysWDy7ZyJL+UzqH+TB7dnbAAX8ICfQkN8KNXZDARIXazy5SLUOARERG5iBqXmx/9eQfbM4pw+Puw7IGruSoqxOyypJE0aVlEROQCDMPgZ3/fyyf7c7H7WPn9lJEKO22UAo+IiMgFvLT+MH/ekoHVAosnDWVk9w5mlySXSYFHRETkPD7afZLffHIQgKdvG8CtA6JNrkiuhAKPiIjIfzmcd4bHV+4C4OHr47nvmm4mVyRXSoFHRETka0ora5j6TipnKmu4pkcH5tza1+ySpAko8IiIiJxlGAZP/GUXh/POEOWw8/Jdw/Cx6avSG+j/ooiIyFm///woq3edxNdm4bV7hmttHS+iwCMiIgJ8eeQ0iz5KB+BnExIY3k23ifAmCjwiItLuFZVV8dj7abjcBt8d2lWTlL2QAo+IiLRrhmEw76+7yXFW0KNTEAu/O0B3PPdCCjwiItKufZB6go/25OBjtbB40lAC/XTXJW+kwCMiIu3WsVOl/PwfewGYPa4PA2NCTa5ImosCj4iItEvVLjePLU+jrMrFNT068MgNPcwuSZqRxu1ERMTrnSwu57OD+fj5WAnwtWH3tfHpgXx2ZtbeAf3X/zMEm1XzdryZAo+IiHi1imoX97z1JUfyS8+7fdHtg+gSFtDCVUlLU+ARERGv9ttPDnEkv5TwQF8GdA2lvMpFRY2Limo3t/aPZvygzmaXKC2gVczhqaysZMiQIVgsFtLS0upt27VrF9dffz3+/v7Exsby/PPPn/P+Dz74gL59++Lv78/AgQNZs2ZNC1UuIiKt2e4TxfzuX0cAeO57g/jTg6NYOW00q350PZ/MupGfJPUxuUJpKa0i8DzxxBN06dLlnNedTifjxo2jW7dupKam8sILL/Dzn/+cN99809Nm8+bN3HXXXTz44IPs2LGDiRMnMnHiRPbs2dOShyAiIq1MVY2bx1fuxOU2mDCoM+P6R5tdkpjI9MDz0Ucf8fHHH/OrX/3qnG3vvvsuVVVV/OEPf6B///5MmjSJH//4x/z617/2tFm8eDG33norjz/+OP369eMXv/gFw4YN45VXXmnJwxARkVZmyadfkZ5TQnigL09/p7/Z5YjJTA08ubm5PPzww/zpT38iMDDwnO0pKSnccMMN+Pn5eV5LSkriwIEDFBYWetqMHTu23vuSkpJISUm54H4rKytxOp31HiIi4j0O5pbw8oZDAPz8O/3pGKybgLZ3pgUewzCYMmUKU6dOZcSIEedtk5OTQ1RUVL3X6p7n5ORctE3d9vNZtGgRoaGhnkdsbOyVHIqIiLQiNS43T6zcRbXL4Ja+kXxn8LlTJqT9afLAM3fuXCwWy0Uf6enpvPzyy5SUlDBv3rymLuGS5s2bR3FxseeRmZnZ4jWIiEjTc1ZU89Aft5GWWUSI3YeF3x2o+2IJ0AyXpc+ePZspU6ZctE2PHj3YsGEDKSkp2O31hxlHjBjBPffcw7Jly4iOjiY3N7fe9rrn0dHRnj/P16Zu+/nY7fZz9isiIm3b8dOlPLhsG4fzzuDva+U3dw4hOtTf7LKklWjywBMREUFERMQl27300kv88pe/9DzPzs4mKSmJ5cuXM2rUKAASExN58sknqa6uxtfXF4Dk5GT69OlDeHi4p8369euZMWOG57OSk5NJTExswqMSEZHW7Isjp5n2TiqFZdVEOey89YORui+W1GPawoNxcXH1ngcHBwPQs2dPYmJiALj77rt5+umnefDBB5kzZw579uxh8eLF/OY3v/G877HHHuPGG2/kxRdfZPz48bz//vts27at3qXrIiLivVamnmDuX3ZR4zYYHBPKmz8YQZRDIztSn+mXpV9MaGgoH3/8MUePHmX48OHMnj2b+fPn88gjj3jajB49mvfee48333yTwYMHs3LlSj788EMGDBhgYuUiItISVu86yeMrd1Jzdq2d5T9MVNiR87IYhmGYXYTZnE4noaGhFBcX43A4zC5HREQa4N+HT3H/21upcrm5Z1Qcv5w4QBOU25nGfH+36hEeERGR89l9ophH/riNKpebbw2M5pnbFHbk4hR4RESkTTl6qpQpb2+htMrF6J4d+c2dQ7BZFXbk4nS3dBERaRMqql1sOpDHL1fv53RpFQO6OnjjvuHYfWxmlyZtgAKPiIi0WrUhJ581u0+yfn8upVUuALp3DGTp/VcT4u9rcoXSVijwiIhIq1RYWsX3l2zmq/xSz2tdwwL41sBoHr6+B510fyxpBAUeERFpdWpcbh7983a+yi+lY5Aftw/ryvhBXRgcE6rJyXJZFHhERKTVWbhmP/8+fJpAPxvvPjyKvtFaMkSujK7SEhGRVmXFtkze/vcxAH79P4MVdqRJKPCIiEirsT2jkKf+tgeAx27pza0DOptckXgLBR4REWkVcoor+OGfUqlyuUnqH8Vjt/Q2uyTxIgo8IiJiOpfb4LH3d5BfUkmfqBBe/J8hWLWYoDQhBR4RETHdm58d4cujBQT62Vhy33CC7bqmRpqWAo+IiJhq94liXvz4AAA//3Z/4jsFmVyReCMFHhERMU1ZVQ2PLd9BjdvgmwOiuWNEjNkliZdS4BEREdP8cvV+juSXEu3wZ9HtA7WooDQbBR4RETHFx3tzeO/LDCyW2vV2wgL9zC5JvJgCj4iItLg8ZwVz/7obgIev78HoXp1Mrki8nQKPiIi0KMMweOIvuygorSKhs4PZ464yuyRpBxR4RESkRb3zxXE2HcjHz8fKbycNwe5jM7skaQcUeEREpMUczjvDL1fvB2DeN/tyVVSIyRVJe6HAIyIiLaKqxs3M5WlU1ri5vncnJid2N7skaUcUeEREpEW8tP4Qu7OKCQ3w5YXvD9atI6RFKfCIiEiz23asgNc2HQZg0e0DiQ71N7kiaW8UeEREpFnVuNw8+bc9uA24fVhXvjWws9klSTukwCMiIs3q/a2ZHMgtISzQl/kTEswuR9opBR4REWk2xeXV/Dr5IAAzx16l1ZTFNAo8IiLSbF5ef4iC0ip6RQZz96g4s8uRdkyBR0REmsWR/DMs3XwMgJ9NSMDXpq8cMY/+9omISLN4dk06NW6DMX0iuPGqCLPLkXZOgUdERJrc54dO8cn+XGxWC0+O10RlMZ8Cj4iINKkal5tfrNoHwH3XdKNXZLDJFYko8IiISBP74kgBB3JLcPj7MGNsb7PLEQEUeEREpIltSM8D4NYB0boMXVoNBR4REWlSmw7UBp6b+0aaXInIfyjwiIhIkzl2qpQjp0rxsVq4tlcns8sR8VDgERGRJrPx7OjOyO4dCPH3Nbkakf9Q4BERkSaz8UA+oNNZ0voo8IiISJMoq6rhiyOnARjTVwsNSuuiwCMiIk1i8+HTVNW4iQkPoGeE1t6R1kWBR0REmsTGr12dZbFYTK5GpD4FHhERuWKGYbDp7PydMX00f0daH9MDz+rVqxk1ahQBAQGEh4czceLEetszMjIYP348gYGBREZG8vjjj1NTU1OvzaZNmxg2bBh2u51evXqxdOnSljsAERHhYO4ZsorKsftYuaZHR7PLETmHj5k7/8tf/sLDDz/Ms88+y80330xNTQ179uzxbHe5XIwfP57o6Gg2b97MyZMn+cEPfoCvry/PPvssAEePHmX8+PFMnTqVd999l/Xr1/PQQw/RuXNnkpKSzDo0EZF2pe501uieHQnws5lcjci5LIZhGGbsuKamhu7du/P000/z4IMPnrfNRx99xIQJE8jOziYqKgqAJUuWMGfOHPLz8/Hz82POnDmsXr26XlCaNGkSRUVFrF27tkG1OJ1OQkNDKS4uxuFwXPnBiYi0M3e+kcKXRwt45rb+/CCxu9nlSDvRmO9v005pbd++naysLKxWK0OHDqVz585885vfrBdcUlJSGDhwoCfsACQlJeF0Otm7d6+nzdixY+t9dlJSEikpKRfcd2VlJU6ns95DREQuT3F5NduOFwKavyOtl2mB58iRIwD8/Oc/56mnnmLVqlWEh4dz0003UVBQAEBOTk69sAN4nufk5Fy0jdPppLy8/Lz7XrRoEaGhoZ5HbGxskx6biEh78vmhU7jcBr0ig4ntEGh2OSLn1eSBZ+7cuVgslos+0tPTcbvdADz55JN873vfY/jw4bz99ttYLBY++OCDpi6rnnnz5lFcXOx5ZGZmNuv+RES8Wd3d0cf00WKD0no1+aTl2bNnM2XKlIu26dGjBydPngQgISHB87rdbqdHjx5kZGQAEB0dzZYtW+q9Nzc317Ot7s+6177exuFwEBAQcN792+127HZ7ww9KRETOq9rlZn167e/gm/tGXaK1iHmaPPBEREQQEXHplD98+HDsdjsHDhzguuuuA6C6uppjx47RrVs3ABITE1m4cCF5eXlERtaeF05OTsbhcHiCUmJiImvWrKn32cnJySQmJjblYYmIyHl8ceQ0RWXVdAzy4+r4DmaXI3JBps3hcTgcTJ06lQULFvDxxx9z4MABpk2bBsAdd9wBwLhx40hISOC+++5j586drFu3jqeeeorp06d7RmimTp3KkSNHeOKJJ0hPT+e1115jxYoVzJw506xDExFpN9bsrh2tTxoQjc2q1ZWl9TJ1HZ4XXngBHx8f7rvvPsrLyxk1ahQbNmwgPDwcAJvNxqpVq5g2bRqJiYkEBQUxefJknnnmGc9nxMfHs3r1ambOnMnixYuJiYnhrbfe0ho8IiLNrMblZt3e2tNZ3xrQ2eRqRC7OtHV4WhOtwyMi0nj/PnyKe976kvBAX7Y+ORYfm+mL90s70ybW4RERkbbNczqrf7TCjrR6+hsqIiKN5nIbrNtbux7atwbqdJa0fgo8IiLSaFuOFnDqTBVhgb4k9tTNQqX1U+AREZFG+2hP7emscQlR+Op0lrQB+lsqIiKN4nIbfLSn9nTWN3U6S9oIBR4REWmU1OOF5JdU4vD34dqencwuR6RBFHhERKRR6q7O+kZCNH4++hqRtkF/U0VEpMHcbsMzf+dbA6NNrkak4RR4RESkwbYdLyTXWUmI3Yfreut0lrQdCjwiItJg72/NAGrvnWX3sZlcjUjDKfCIiEiDFJVVsWpX7emse0bFmVyNSOMo8IiISIOsTD1BVY2bhM4OhsSGmV2OSKMo8IiIyCUZhsF7W2pPZ91zTRwWi8XkikQaR4FHREQu6YsjBRzJLyXIz8ZtQ7qaXY5IoynwiIjIJb375XEAbhvalWC7j8nViDSeAo+IiFzUqTOVnjuj3321JitL26TAIyIiF/XBthNUuwwGx4YxoGuo2eWIXBYFHhERuSC32+C9LbWns3QpurRlCjwiInJB/zp8isyCckL8ffj2oC5mlyNy2RR4RETkgt47O1n5e8NiCPDTysrSdinwiIjIeeWVVPDJ/jwA7tbpLGnjFHhEROS8/pKahcttMCwujKuiQswuR+SKKPCIiMg5DMNgxbZMACaN1OiOtH0KPCIico4tRws4eqp2ZeXxgzqbXY7IFVPgERGRcyzfWju68+3BXQjSysriBRR4RESknuLyatbsOQnA/4yMNbkakaahwCMiIvX8Y2c2FdVurooKZmhsmNnliDQJBR4REalnxdnTWf8zIhaLxWJyNSJNQ4FHREQ89mQVszurGF+bhduHxZhdjkiTUeARERGPukvRx/WPpkOQn8nViDQdBR4REQGgotrFhzuyALhzhCYri3dR4BEREQCS9+XirKiha1gA1/XqZHY5Ik1KgUdERAD47GA+ABMGdcZq1WRl8S4KPCIigmEYbP7qNACjNbojXkiBR0REyCwoJ6uoHB+rhZHdw80uR6TJKfCIiAibvzoFwNC4MAL9dCsJ8T4KPCIiQsqR2tNZiT06mlyJSPNQ4BERaee+Pn8nsafm74h3UuAREWnnvso/Q35JJXYfK0PjwswuR6RZKPCIiLRzdaM7I7qH4+9rM7kakeZhauA5ePAgt912G506dcLhcHDdddexcePGem0yMjIYP348gYGBREZG8vjjj1NTU1OvzaZNmxg2bBh2u51evXqxdOnSFjwKEZG2bfPhs5ej63SWeDFTA8+ECROoqalhw4YNpKamMnjwYCZMmEBOTg4ALpeL8ePHU1VVxebNm1m2bBlLly5l/vz5ns84evQo48ePZ8yYMaSlpTFjxgweeugh1q1bZ9ZhiYi0GW63wRdH6+bvaMKyeC+LYRiGGTs+deoUERERfPbZZ1x//fUAlJSU4HA4SE5OZuzYsXz00UdMmDCB7OxsoqKiAFiyZAlz5swhPz8fPz8/5syZw+rVq9mzZ4/nsydNmkRRURFr165tUC1Op5PQ0FCKi4txOBxNf7AiIq3U3uxixr/0OUF+NtIWjMPXppkO0nY05vvbtL/ZHTt2pE+fPvzxj3+ktLSUmpoa3njjDSIjIxk+fDgAKSkpDBw40BN2AJKSknA6nezdu9fTZuzYsfU+OykpiZSUlJY7GBGRNirl7Pydq+M7KOyIVzNtdSmLxcInn3zCxIkTCQkJwWq1EhkZydq1awkPr13lMycnp17YATzP6057XaiN0+mkvLycgICAc/ZdWVlJZWWl57nT6WzSYxMRaSs8t5PQ/B3xck0e5+fOnYvFYrnoIz09HcMwmD59OpGRkfzrX/9iy5YtTJw4kW9/+9ucPHmyqcuqZ9GiRYSGhnoesbGxzbo/EZHWqMblZsvRAkDzd8T7NfkIz+zZs5kyZcpF2/To0YMNGzawatUqCgsLPefdXnvtNZKTk1m2bBlz584lOjqaLVu21Htvbm4uANHR0Z4/6177ehuHw3He0R2AefPmMWvWLM9zp9Op0CMi7c7urGLOVNYQGuBLQmfNXxTv1uSBJyIigoiIiEu2KysrA8BqrT/IZLVacbvdACQmJrJw4ULy8vKIjIwEIDk5GYfDQUJCgqfNmjVr6n1GcnIyiYmJF9y33W7Hbrc3/KBERLyQZ3XlHh2xWi0mVyPSvEyboZaYmEh4eDiTJ09m586dHDx4kMcff9xzmTnAuHHjSEhI4L777mPnzp2sW7eOp556iunTp3sCy9SpUzly5AhPPPEE6enpvPbaa6xYsYKZM2eadWgiIm1Cyle6HF3aD9MCT6dOnVi7di1nzpzh5ptvZsSIEXz++ef8/e9/Z/DgwQDYbDZWrVqFzWYjMTGRe++9lx/84Ac888wzns+Jj49n9erVJCcnM3jwYF588UXeeustkpKSzDo0EZFWr6rGzbbjmr8j7Ydp6/C0JlqHR0Tamx0ZhXz3tc2EB/qy/WffwGLRKS1pe9rEOjwiImKe1OOFAAzvFq6wI+2CAo+ISDtUF3iGdQs3uRKRlqHAIyLSzhiGwbazgWdEtw4mVyPSMhR4RETamROF5eSXVOJrszAoJtTsckRahAKPiEg7U3d1Vv8uofj72kyuRqRlKPCIiLQz247Vnc7S/B1pPxR4RETamboJyyO6K/BI+6HAIyLSjjgrqjmQWwLoCi1pXxR4RETakR0ZRRgGxHUIJDLE3+xyRFqMAo+ISDviOZ2l0R1pZxR4RETakdSzV2jpdJa0Nwo8IiLtRI3LzY6MIkATlqX9UeAREWkn0nNKKKtyEWL34arIELPLEWlRCjwiIu1E3fydod3CsVp1w1BpXxR4RETaiW2asCztmAKPiEg7kXqsdsKyAo+0Rwo8IiLtQHZROdnFFdisFgbHhpldjkiLU+AREWkH6ubv9OscQpDdx+RqRFqeAo+ISDuwPaM28AyP0+ksaZ8UeERE2oFdJ4oBGBIXZm4hIiZR4BER8XLVLjd7s2sDz6CYMHOLETGJAo+IiJc7mFtCRbWbELsP8R2DzC5HxBQKPCIiXq7udNbAmFAtOCjtlgKPiIiX23WiCNDpLGnfFHhERLzczsyzE5ZjQ02uRMQ8CjwiIl6sotrFgdwSQCM80r4p8IiIeLG92U5cboNOwXY6h/qbXY6IaRR4RES8WN38ncExoVgsmrAs7ZcCj4iIF6u7Qkuns6S9U+AREfFiOzOLABikCcvSzinwiIh4qeLyao6cKgVgsEZ4pJ1T4BER8VJ7smpPZ8WEB9AhyM/kakTMpcAjIuKldtZNWI4NM7UOkdZAgUdExEvtOrvg4OAYzd8RUeAREfFSuqWEyH8o8IiIeKH8kkqyiyuwWGBAV43wiCjwiIh4obrRnV4RwQTbfcwtRqQVUOAREfFCnvV3dDpLBFDgERHxSjvPrrA8WAsOigAKPCIiXscwjK/dQyvM1FpEWgsFHhERL5NVVE5hWTW+Ngt9O4eYXY5Iq9BsgWfhwoWMHj2awMBAwsLCztsmIyOD8ePHExgYSGRkJI8//jg1NTX12mzatIlhw4Zht9vp1asXS5cuPedzXn31Vbp3746/vz+jRo1iy5YtzXBEIiJtw75sJwC9I0Ow+9hMrkakdWi2wFNVVcUdd9zBtGnTzrvd5XIxfvx4qqqq2Lx5M8uWLWPp0qXMnz/f0+bo0aOMHz+eMWPGkJaWxowZM3jooYdYt26dp83y5cuZNWsWCxYsYPv27QwePJikpCTy8vKa69BERFq1fSdrA0+/zg6TKxFpPSyGYRjNuYOlS5cyY8YMioqK6r3+0UcfMWHCBLKzs4mKigJgyZIlzJkzh/z8fPz8/JgzZw6rV69mz549nvdNmjSJoqIi1q5dC8CoUaMYOXIkr7zyCgBut5vY2Fh+9KMfMXfu3AbV6HQ6CQ0Npbi4GIdDvyBEpG175I/b+HhfLj+bkMCD18WbXY5Is2nM97dpc3hSUlIYOHCgJ+wAJCUl4XQ62bt3r6fN2LFj670vKSmJlJQUoHYUKTU1tV4bq9XK2LFjPW3Op7KyEqfTWe8hIuIt6kZ4EjTCI+JhWuDJycmpF3YAz/OcnJyLtnE6nZSXl3Pq1ClcLtd529R9xvksWrSI0NBQzyM2NrYpDklExHTF5dWcKCwHFHhEvq5RgWfu3LlYLJaLPtLT05ur1iYzb948iouLPY/MzEyzSxIRaRL7z47udA0LIDTQ1+RqRFqPRq03Pnv2bKZMmXLRNj169GjQZ0VHR59zNVVubq5nW92fda99vY3D4SAgIACbzYbNZjtvm7rPOB+73Y7dbm9QnSIibUndFVoJXTS6I/J1jQo8ERERRERENMmOExMTWbhwIXl5eURGRgKQnJyMw+EgISHB02bNmjX13pecnExiYiIAfn5+DB8+nPXr1zNx4kSgdtLy+vXrefTRR5ukThGRtkTzd0TOr9nm8GRkZJCWlkZGRgYul4u0tDTS0tI4c+YMAOPGjSMhIYH77ruPnTt3sm7dOp566immT5/uGX2ZOnUqR44c4YknniA9PZ3XXnuNFStWMHPmTM9+Zs2axe9+9zuWLVvG/v37mTZtGqWlpdx///3NdWgiIq2WRnhEzq/ZbqE7f/58li1b5nk+dOhQADZu3MhNN92EzWZj1apVTJs2jcTERIKCgpg8eTLPPPOM5z3x8fGsXr2amTNnsnjxYmJiYnjrrbdISkrytLnzzjvJz89n/vz55OTkMGTIENauXXvORGYREW9XVePmUF4JoBEekf/W7OvwtAVah0dEvMH+k06+ufhfhPj7sGvBOCwWi9kliTSrNrEOj4iINC3P6azODoUdkf+iwCMi4iU8E5Y1f0fkHAo8IiJe4usjPCJSnwKPiIgXMAxDIzwiF6HAIyLiBbKLKygur8bXZqF3ZIjZ5Yi0Ogo8IiJeoO50Vs+IYPx89Ktd5L/pp0JExAtowUGRi1PgERHxAvtOFgOasCxyIQo8IiJeQBOWRS5OgUdEpI0rLq8ms6Ac0AiPyIUo8IiItHHpZ0d3uoYFEBboZ3I1Iq2TAo+ISBtXdzqrn0Z3RC5IgUdEpI37zwrLWn9H5EIUeERE2rg9ZwNP/66hJlci0nop8IiItGEV1S4O5ZYAMECBR+SCFHhERNqwg7kl1LgNwgN96RLqb3Y5Iq2WAo+ISBu2J6v2dNaArqFYLBaTqxFpvRR4RETasD3ZtSss9++i01kiF6PAIyLShu3Nqg08AzV/R+SiFHhERNqoapeb/Tl1E5a1Bo/IxSjwiIi0UYfzzlBV4ybE34e4DoFmlyPSqinwiIi0UXuy6ubvODRhWeQSFHhERNqovWcXHBygCcsil6TAIyLSRtWN8GjBQZFLU+AREWmDXG7jPyM8mrAsckkKPCIibdDRU2cor3YR4GsjvlOw2eWItHoKPCIibVDdCssJXRzYrJqwLHIpCjwiIm2QZ/5OF53OEmkIBR4RkTbIc0sJTVgWaRAFHhGRNsbtNtibpUvSRRpDgUdEpI3JLCyjpLIGP5uV3lGasCzSEAo8IiJtTN2E5b6dQ/C16de4SEPoJ0VEpI3xzN/R6SyRBlPgERFpY+qu0BqoCcsiDabAIyLShhiGVlgWuRwKPCIibcjJ4goKSqvwsVq4KirE7HJE2gwFHhGRNmT32dNZvaNC8Pe1mVyNSNuhwCMi0obsPlEbeAZp/o5IoyjwiIi0ITtPFAEwMEaBR6QxFHhERNoIwzA8p7QGKfCINIoCj4hIG3GisJyismp8bRb6RGvCskhjNFvgWbhwIaNHjyYwMJCwsLBztu/cuZO77rqL2NhYAgIC6NevH4sXLz6n3aZNmxg2bBh2u51evXqxdOnSc9q8+uqrdO/eHX9/f0aNGsWWLVua4YhERMy16+z8nb7RDuw+mrAs0hjNFniqqqq44447mDZt2nm3p6amEhkZyTvvvMPevXt58sknmTdvHq+88oqnzdGjRxk/fjxjxowhLS2NGTNm8NBDD7Fu3TpPm+XLlzNr1iwWLFjA9u3bGTx4MElJSeTl5TXXoYmImGJXVhGg01kil8NiGIbRnDtYunQpM2bMoKio6JJtp0+fzv79+9mwYQMAc+bMYfXq1ezZs8fTZtKkSRQVFbF27VoARo0axciRIz1Bye12Exsby49+9CPmzp3boBqdTiehoaEUFxfjcGghLxFpne7+3Rds/uo0z31vIHeOjDO7HBHTNeb7u1XN4SkuLqZDhw6e5ykpKYwdO7Zem6SkJFJSUoDaUaTU1NR6baxWK2PHjvW0OZ/KykqcTme9h4hIa+Z2/2fC8sCuYeYWI9IGtZrAs3nzZpYvX84jjzzieS0nJ4eoqKh67aKionA6nZSXl3Pq1ClcLtd52+Tk5FxwX4sWLSI0NNTziI2NbdqDERFpYscLyiipqMHuY6V3VLDZ5Yi0OY0KPHPnzsVisVz0kZ6e3ugi9uzZw2233caCBQsYN25co9/fWPPmzaO4uNjzyMzMbPZ9iohciV1n199J6OLA19Zq/q0q0mb4NKbx7NmzmTJlykXb9OjRo1EF7Nu3j1tuuYVHHnmEp556qt626OhocnNz672Wm5uLw+EgICAAm82GzWY7b5vo6OgL7tNut2O32xtVp4iImbTCssiVaVTgiYiIICIiosl2vnfvXm6++WYmT57MwoULz9memJjImjVr6r2WnJxMYmIiAH5+fgwfPpz169czceJEoHbS8vr163n00UebrE4REbPtqpu/ExNmbiEibVSjAk9jZGRkUFBQQEZGBi6Xi7S0NAB69epFcHAwe/bs4eabbyYpKYlZs2Z55tzYbDZPqJo6dSqvvPIKTzzxBA888AAbNmxgxYoVrF692rOfWbNmMXnyZEaMGMHVV1/Nb3/7W0pLS7n//vub69BERFqUy22wVyssi1yRZgs88+fPZ9myZZ7nQ4cOBWDjxo3cdNNNrFy5kvz8fN555x3eeecdT7tu3bpx7NgxAOLj41m9ejUzZ85k8eLFxMTE8NZbb5GUlORpf+edd5Kfn8/8+fPJyclhyJAhrF279pyJzCIibdXRU2corXIR4GujZ4QmLItcjmZfh6ct0Do8ItKa/XX7CWat2MnI7uF8MHW02eWItBptdh0eERE5V90tJbT+jsjlU+AREWnldId0kSunwCMi0orVuNzsza67QkuBR+RyKfCIiLRih/PPUFHtJtjuQ3zHILPLEWmzFHhERFqxuvk7A7o6sFotJlcj0nYp8IiItGKeFZa14KDIFVHgERFppapdbjak5wEwWIFH5Ioo8IiItFKrdmWTVVROp2A/bukXaXY5Im2aAo+ISCtkGAZvfHoEgPuvjcff12ZyRSJtmwKPiEgrtOlAPuk5JQT52bh3VDezyxFp8xR4RERaodc//QqAu0fFERroa3I1Im2fAo+ISCuTeryQLUcL8LVZePC6HmaXI+IVFHhERFqZJWdHd747tCvRof4mVyPiHRR4RERakcN5JSTvy8VigUdu6Gl2OSJeQ4FHRKQVqbsy6xv9ougVGWxyNSLeQ4FHRKSVyCmu4MO0LACm3qTRHZGmpMAjItJKvL81g2qXwdXdOzAsLtzsckS8igKPiEgr4HIbrNiaCcA918SZXI2I91HgERFpBT47lE92cQVhgb4k9Y82uxwRr6PAIyLSCizfUju6892hXXUbCZFmoMAjImKy/JJKPtmfC8CkkTqdJdIcFHhEREy2MvUENW6DoXFh9IkOMbscEa+kwCMiYiLDMFi+NQOAuzS6I9JsFHhEREz0xZECjp0uI8jPxvhBnc0uR8RrKfCIiJjo/bOjO98Z0pUgu4/J1Yh4LwUeERGTFJVV8dGeHADuujrW5GpEvJsCj4iISf62I4uqGjf9OjsY2DXU7HJEvJoCj4iICVxug3e+OA7Uju5YLBaTKxLxbgo8IiImWL37JF/ll+Lw92Hi0K5mlyPi9RR4RERamMttsPiTgwA8dH0PHP6+Jlck4v0UeEREWtg/d2bzVX4poQG+3H9td7PLEWkXFHhERFpQjcvN4vWHAHjkhh6EaHRHpEUo8IiItKC/p2Vz9FQp4YG+TB7d3exyRNoNBR4RkRZS43Lz0oa60Z2eBGuhQZEWo8AjItJC/roji+Ony+gY5McPEruZXY5Iu6LAIyLSAqpdbl4+O7rzwxt76DYSIi1MgUdEpAX8bUcWmQXldAq2c9813c0uR6TdUeAREWlmbrfBG59+BcAjN8QT4GczuSKR9kdjqiLS7lRUu/jnzmyWbj5GRkEZf374GgY0472s1qfn8VV+KSH+Ptx1dVyz7UdELkyBR0TajVxnBe98cZz3vszgdGmV5/XffnKItyaPaLb9Ljk7unPvNd207o6ISZrtlNbChQsZPXo0gYGBhIWFXbTt6dOniYmJwWKxUFRUVG/bpk2bGDZsGHa7nV69erF06dJz3v/qq6/SvXt3/P39GTVqFFu2bGm6AxERr7DxQB43PL+Rlzcc5nRpFV1C/Zl2U08sFvhkfy6HckuaZb/bjhWQerwQP5uV+7Xujohpmi3wVFVVcccddzBt2rRLtn3wwQcZNGjQOa8fPXqU8ePHM2bMGNLS0pgxYwYPPfQQ69at87RZvnw5s2bNYsGCBWzfvp3BgweTlJREXl5ekx6PiLRdKV+dZuqfUqmscTM4NoxX7x7GZ0+MYc6tfRmXEAXAG58daZZ9L/m09nNvH9aVSId/s+xDRC6t2QLP008/zcyZMxk4cOBF273++usUFRXxk5/85JxtS5YsIT4+nhdffJF+/frx6KOP8v3vf5/f/OY3nja//vWvefjhh7n//vtJSEhgyZIlBAYG8oc//KHJj0lEGm7TgTzmrNzF33acoPBrp49a2o6MQh5atpXKGjdj+0Wycmoi4wd1xsdW++vvhzf2BODvaVmcLC5v0n0fyi3hk/25WCzw8A09mvSzRaRxTJ3Ds2/fPp555hm+/PJLjhw5919XKSkpjB07tt5rSUlJzJgxA6gdRUpNTWXevHme7VarlbFjx5KSknLB/VZWVlJZWel57nQ6r/BIRFq/nZlFvPnZEU4UlRMW4EtogC9hgb6EBfoR3ymQ3pEh9IwIbpIriP6elsWsFTtxuQ2Wb8vEaoER3TpwS79IunUMpLzaRUW1m/IqF27DICY8gG4dg+jeMajB+y8srSL1eCGpGYWkHiskPcdJ/y6hfG94DN8cEE2Q3Yf9J51MeXsrpVUuru3VkVfuHoavrf6/84bFhXN1fAe2HC3g9/86ylMTEq74+Ou8eXbUaFxCFD0jgpvsc0Wk8UwLPJWVldx111288MILxMXFnTfw5OTkEBUVVe+1qKgonE4n5eXlFBYW4nK5ztsmPT39gvtetGgRTz/9dNMciEgLKCitItDPhr9v48PIjoxCFq8/xKYD+Zdsa7FAbHggPSOCiOsQSFzH2j+7hgVQ7XJTVF5NUVkVxeXVBPjaGD+oM4F+9X+NrNiayZy/7sIw4NpeHTl9por0nBK2HCtgy7GCS9YQ5bDTN9rB6J4dGd2zEwldHNisFqpdblKPF7LxQB6b0vM5cJ45NylHTpNy5DTz/76HWwdE89nBfIrLqxneLZw37xtxwf6bdmNPthwt4M9bMvjRzb0JDbzyicU5xRV8mJYF/GcUSUTM06jAM3fuXJ577rmLttm/fz99+/a95GfNmzePfv36ce+99zamhCYxb948Zs2a5XnudDqJjY1t8TpELsQwDPZmO0nel8sn+3PZm+3Ex2rhqqgQBseGMigmjITODsICfQnx9yXE3wdfm5XyKhcZBWUcP11KRkEZnx06xWcHa4OOzWrhtiFdGJcQTUlFNcXltY9TZ6o4kn+GQ3lnKCitIqOgjIyCsgbV+eya/dx/bTyTE7sTGujLss3HWPCPvQDcPSqOX942AKvVQmZBGev357LpYD5nKmrw97WdfdSOtmQWlnP8dClFZdXkOivJdebz6dm6QwN8SejsYE9WMSWVNfX23zMiiOHdwhnRrQO9o4L5/NAp/rL9BMdOl/HX7bVho38XB3+YMvKiKxvf1CeCvtEhpOeU8KcvjvHozb0b9z/sPP7w76NUuwyu7t6BYXHhV/x5InJlGhV4Zs+ezZQpUy7apkePhp2n3rBhA7t372blypVA7S94gE6dOvHkk0/y9NNPEx0dTW5ubr335ebm4nA4CAgIwGazYbPZztsmOjr6gvu22+3Y7fYG1Slyub48cpo/phwn/0wlzvJqSipqcFZUU1ntPqet3ddKsN2HQD8bwXYf8koqOVlcUa9Njdtg30kn+046+fOWzHM/w8dKZc25n22zWrh9aFemj+lF905BF6359JlKDuae4djZwJRxujb8ZBWV4+9jJTTQj7Czp8L2ZjvJKCjj18kHeePTr7iudyfW7a39WXzwunieGt8Pi8UCQGyHQKZcG8+Ua+Mvuv+isiqOniple0YRKV+d4ssjBRSXV5Ny5DQAHYL8uPGqCG7qE8H1vSPoEORX7/1D48J59OZepB4v5C/bs3CWV/PMbf0JDbj4iI3FYuGHN/Zg5vKdLN18jIeu73FZo2l10jKLWLb5GABTb9LcHZHWoFGBJyIigoiIiCbZ8V/+8hfKy/8zQXDr1q088MAD/Otf/6Jnz9rh38TERNasWVPvfcnJySQmJgLg5+fH8OHDWb9+PRMnTgTA7Xazfv16Hn300SapU6Sxcp0VPLtmP39Py27we6pcbkoq6o9eBPrZuKF3BGMTohjTJ4LKGjc7M4vYeaKYXSeKOJx3hpKKGsqrXQCesOPw96FbxyDiOgbSs1MQ3x8eS1zHwAbV0THYTmKwncSeHS/ZtsblZvXuk7y28SsO5JZ4ws6jY3oxe9xVnrDTGGGBfgyN82NoXDgPXhdPjcvN7qxi9p8soX8XBwO7hmK1XvxzLRYLI7p3YET3Do3a94RBXfjVuoNkFZWzMvUE915zeTf3zCwo80ySHtMngpuuiryszxGRptVsc3gyMjIoKCggIyMDl8tFWloaAL169SI4ONgTauqcOnUKgH79+nnW7Zk6dSqvvPIKTzzxBA888AAbNmxgxYoVrF692vO+WbNmMXnyZEaMGMHVV1/Nb3/7W0pLS7n//vub69BEzquqxs3b/z7KS+sPUVrlwmKBSSPjuK5XJxwBPoT4++Lw98Hf18bXs4DbqF35t7SyhtLK2j/9fW2M6B5+zihDl7AAvjmwc73XalxuzlTWUFJRQ4i/D2GB9Uc9mouPzcptQ7ry7UFd2JCex/tbM7iuV6dLjuI0dh9D48IZ2gKnhHxtVh66Pp6n/7mPxesPceNVEcR2aFhQrFNcXs39S7dy6kwV/To7ePnuYZcMaCLSMpot8MyfP59ly5Z5ng8dOhSAjRs3ctNNNzXoM+Lj41m9ejUzZ85k8eLFxMTE8NZbb5GUlORpc+edd5Kfn8/8+fPJyclhyJAhrF279pyJzCJNqdrl5kBOCek5JaSfdJKeU8Le7GIKy6oBGBoXxi9uG9Cstyuo42OzEhbo12JB579ZrRbGJkQxNqHt/8xNGhnHe19mcCjvDPf+/ks++GFig9fOqapxM+2dVA7nnSHKYecPU0YQrDuii7QaFqNu8kw75nQ6CQ0Npbi4GIfDYXY50grll1Sy7VgBOzKL2JFRyK4TxeedL9Mp2I85t/ble8Ni9C/7NirXWcEdS1LIKCjjqqhglj+SSHjQxcOkYRg8vnIXK1NPEORnY8XURPp3af6wK9LeNeb7W4EHBR5vZhgG5dUuisurKSqrvSqpsLSK06VVnD5TRUFpJQVl1XQNC2BUfAeGdw/HcfZeR0VlVXy0J4d/pGXzxdHT/PdPisPfh4QuDvpGO+jXOYQ+0Q76Rodc0WRXaR0yC8r4/pLN5DorGRQTyrsPjbrgPbAO55WwaE0669PzsFrg95NHMqav5u2ItAQFnkZS4PEu2UXlbDqQz8YDeaR8dZoz/3Up88VYLNAv2kGnEDspX52i2vWfH4++0SEM6xbOsLhwhsaFEd8xSKM4XuxQbgl3vvkFBaVVXB3fgVnfuIq+0SGeU4d5zgp+88khlm/NwG3UXg33i9sGcPco3Q1dpKUo8DSSAs+Vc7kNth0r4GRxBSO6hxMTfu5kz4LSKjam55GWWURBaRWFZVUUltUuZNe9YxD/MzKGbw7o3KARkn3ZTtbsPklJRTVVLoNql5uqGjcHc2vn1fw3H6uFsEBfHAG+hAX40jHYTscgPzoG+xEa4MvhvDNsOVrAsdP115/p19nBdwZ3YcKgzo2ewCpt356sYu5684t66/90DvWnV2QwqccLKauqvUJuXEIUc77ZV6spi7QwBZ5GUuC5PHUhZ83uk6zZk0N+yX9u1xHfKYjrenVidM+OHD+76Fzq8ULcl/jb5vD34btDu3LHiFj6Rod47ncE4HYbrE/P4w+fH/Wsy3I+FgsMjQ3j5r6R3HhVJD0iggj0szXoMulcZwVbjhaQ66zgpj4R9IoMuXRHiFfbdaKIlzccZl+2k6yi+vfaGhoXxk+/1Y+RjbwEXkSahgJPIynwXNq/DuXzyb5cCsqqKSit5PSZKnKcFRSdvSoJasNKfEQwe7KKcV0g2fSNDuHGqyKIDvWnQ1DtlUUh/j78+9Aplm/L5EThf75QbFYL0Q5/YjsE0CUsgO3HCz0jMDarhaT+tfcn8rVZ8fOx4muzEhFi57penc5ZkE6kKZRUVHMwt4QDOWfoHOrPTX0iLmu9IRFpGgo8jaTAc3Fv//soT/9z33m3hfj7kNQ/mvGDOnNtz074+VhxVlTzxVen+fzwKbYcLSAixM43EqK4uW/keU911XG7Df791Sne35LJJ/tzz3sVVGiAL3ddHccPErvRJSygyY5RRETaHgWeRlLgOT/DMHjx44O8svEwAN8e3IUhsWF0CPKlQ1DtHJjeUcHYfZr+qiS32yD/TCUnCss4UVhOZkEZESF2vj24yzk3qxQRkfapMd/f+uZoBXKdFZRW1hDfKajVDI+73AZPfbiHP2/JAOAn465i+pheLVaf1WohyuFPlMOf4Ze3wr+IiIiHAo8JDMMgPaeE5H25JO/LZXdWMQBxHQJJ6h/FuP7RDIsLx2bCJc8ut8HhvDP8Jvkga/fmYLXALycO1KW2IiLSpumUFi17SmvzV6eY99fdHP/a5c8WS+19fKq+NmelU7CdEd3CSejioF/n2oXtuoYFNPkIi8tt8O/Dp9j81WnSMgvZfaKY0rOX2vrZrCyeNOScezeJiIi0Bjql1Uol78tl+nvbqapxY/excn3vTmcn80YRZLfx2cF81u3NZf3+XE6dqWTt3hzW7s3xvN/Px4qfzYqPzYKP1YKP1UqHID+6hgfQNSyAmPAAYsID6RkRRLeOQfj5WC9YS8bpMlZsy2Rl6glynBX1tgX62RgUE8rMsVcxqsel75otIiLS2mmEh5YZ4flwRxazP9iJy20wLiGK39w5hKAL3Fiw2uVm27FC9mYXs++kk33ZTg7nnaHmUovYfI3NaqFbh0B6RAQTFuiL2zAwDHAbBieLKthyrMDTNizQl6SEaIZ1C2NIbDi9IoNNOZ0mIiLSGLpKq5GaO/D8KeUY8/+xF8OA24d15fnvDaq3oF5DVNW4yXVW4HIb1Ljd1LgNqmsM8s9UkFVYzomicrIKy8koKONIfuklb6dgscD1vSO4c0QsYxMim+VKKxERkeakU1qtyGubDvP82gMATE7sxoJv97+s+y/5+VgvcGuDc+/IbBgGeSWVHM47w1f5ZyircmG1gNViwWKx4O9r5aY+kXTVOjYiItJOKPA0o7TMIk/Y+dHNvZj1jata5LJui+U/l3Rf26tTs+9PRESktVPgaUZDYsP46bf6AvDIDT1NrkZERKT9UuBpZgo6IiIi5mvczFkRERGRNkiBR0RERLyeAo+IiIh4PQUeERER8XoKPCIiIuL1FHhERETE6ynwiIiIiNdT4BERERGvp8AjIiIiXk+BR0RERLyeAo+IiIh4PQUeERER8XoKPCIiIuL1dLd0wDAMAJxOp8mViIiISEPVfW/XfY9fjAIPUFJSAkBsbKzJlYiIiEhjlZSUEBoaetE2FqMhscjLud1usrOzCQkJwWKxNOlnO51OYmNjyczMxOFwNOlnS33q65ajvm456uuWo75uOU3V14ZhUFJSQpcuXbBaLz5LRyM8gNVqJSYmpln34XA49APUQtTXLUd93XLU1y1Hfd1ymqKvLzWyU0eTlkVERMTrKfCIiIiI11PgaWZ2u50FCxZgt9vNLsXrqa9bjvq65aivW476uuWY0deatCwiIiJeTyM8IiIi4vUUeERERMTrKfCIiIiI11PgEREREa+nwNPMXn31Vbp3746/vz+jRo1iy5YtZpfUpi1atIiRI0cSEhJCZGQkEydO5MCBA/XaVFRUMH36dDp27EhwcDDf+973yM3NNali7/F///d/WCwWZsyY4XlNfd10srKyuPfee+nYsSMBAQEMHDiQbdu2ebYbhsH8+fPp3LkzAQEBjB07lkOHDplYcdvlcrn42c9+Rnx8PAEBAfTs2ZNf/OIX9e7HpP6+PJ999hnf/va36dKlCxaLhQ8//LDe9ob0a0FBAffccw8Oh4OwsDAefPBBzpw5c8W1KfA0o+XLlzNr1iwWLFjA9u3bGTx4MElJSeTl5ZldWpv16aefMn36dL744guSk5Oprq5m3LhxlJaWetrMnDmTf/7zn3zwwQd8+umnZGdnc/vtt5tYddu3detW3njjDQYNGlTvdfV10ygsLOTaa6/F19eXjz76iH379vHiiy8SHh7uafP888/z0ksvsWTJEr788kuCgoJISkqioqLCxMrbpueee47XX3+dV155hf379/Pcc8/x/PPP8/LLL3vaqL8vT2lpKYMHD+bVV1897/aG9Os999zD3r17SU5OZtWqVXz22Wc88sgjV16cIc3m6quvNqZPn+557nK5jC5duhiLFi0ysSrvkpeXZwDGp59+ahiGYRQVFRm+vr7GBx984Gmzf/9+AzBSUlLMKrNNKykpMXr37m0kJycbN954o/HYY48ZhqG+bkpz5swxrrvuugtud7vdRnR0tPHCCy94XisqKjLsdrvx5z//uSVK9Crjx483HnjggXqv3X777cY999xjGIb6u6kAxt/+9jfP84b06759+wzA2Lp1q6fNRx99ZFgsFiMrK+uK6tEITzOpqqoiNTWVsWPHel6zWq2MHTuWlJQUEyvzLsXFxQB06NABgNTUVKqrq+v1e9++fYmLi1O/X6bp06czfvz4en0K6uum9I9//IMRI0Zwxx13EBkZydChQ/nd737n2X706FFycnLq9XVoaCijRo1SX1+G0aNHs379eg4ePAjAzp07+fzzz/nmN78JqL+bS0P6NSUlhbCwMEaMGOFpM3bsWKxWK19++eUV7V83D20mp06dwuVyERUVVe/1qKgo0tPTTarKu7jdbmbMmMG1117LgAEDAMjJycHPz4+wsLB6baOiosjJyTGhyrbt/fffZ/v27WzduvWcberrpnPkyBFef/11Zs2axU9/+lO2bt3Kj3/8Y/z8/Jg8ebKnP8/3+0R93Xhz587F6XTSt29fbDYbLpeLhQsXcs899wCov5tJQ/o1JyeHyMjIett9fHzo0KHDFfe9Ao+0WdOnT2fPnj18/vnnZpfilTIzM3nsscdITk7G39/f7HK8mtvtZsSIETz77LMADB06lD179rBkyRImT55scnXeZ8WKFbz77ru899579O/fn7S0NGbMmEGXLl3U315Mp7SaSadOnbDZbOdcsZKbm0t0dLRJVXmPRx99lFWrVrFx40ZiYmI8r0dHR1NVVUVRUVG99ur3xktNTSUvL49hw4bh4+ODj48Pn376KS+99BI+Pj5ERUWpr5tI586dSUhIqPdav379yMjIAPD0p36fNI3HH3+cuXPnMmnSJAYOHMh9993HzJkzWbRoEaD+bi4N6dfo6OhzLuypqamhoKDgivtegaeZ+Pn5MXz4cNavX+95ze12s379ehITE02srG0zDINHH32Uv/3tb2zYsIH4+Ph624cPH46vr2+9fj9w4AAZGRnq90a65ZZb2L17N2lpaZ7HiBEjuOeeezz/rb5uGtdee+05yyscPHiQbt26ARAfH090dHS9vnY6nXz55Zfq68tQVlaG1Vr/689ms+F2uwH1d3NpSL8mJiZSVFREamqqp82GDRtwu92MGjXqygq4oinPclHvv/++YbfbjaVLlxr79u0zHnnkESMsLMzIyckxu7Q2a9q0aUZoaKixadMm4+TJk55HWVmZp83UqVONuLg4Y8OGDca2bduMxMREIzEx0cSqvcfXr9IyDPV1U9myZYvh4+NjLFy40Dh06JDx7rvvGoGBgcY777zjafN///d/RlhYmPH3v//d2LVrl3HbbbcZ8fHxRnl5uYmVt02TJ082unbtaqxatco4evSo8de//tXo1KmT8cQTT3jaqL8vT0lJibFjxw5jx44dBmD8+te/Nnbs2GEcP37cMIyG9eutt95qDB061Pjyyy+Nzz//3Ojdu7dx1113XXFtCjzN7OWXXzbi4uIMPz8/4+qrrza++OILs0tq04DzPt5++21Pm/LycuN///d/jfDwcCMwMND47ne/a5w8edK8or3Ifwce9XXT+ec//2kMGDDAsNvtRt++fY0333yz3na322387Gc/M6Kiogy73W7ccsstxoEDB0yqtm1zOp3GY489ZsTFxRn+/v5Gjx49jCeffNKorKz0tFF/X56NGzee93f05MmTDcNoWL+ePn3auOuuu4zg4GDD4XAY999/v1FSUnLFtVkM42tLS4qIiIh4Ic3hEREREa+nwCMiIiJeT4FHREREvJ4Cj4iIiHg9BR4RERHxego8IiIi4vUUeERERMTrKfCIiIiI11PgEREREa+nwCMiIiJeT4FHREREvJ4Cj4iIiHi9/wdL0/FVFsiLiQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Deep Deterministic Policy Gradient (DDPG)\n",
    "-----------------------------------------\n",
    "An algorithm concurrently learns a Q-function and a policy.\n",
    "It uses off-policy data and the Bellman equation to learn the Q-function,\n",
    "and uses the Q-function to learn the policy.\n",
    "\n",
    "Reference\n",
    "---------\n",
    "Deterministic Policy Gradient Algorithms, Silver et al. 2014\n",
    "Continuous Control With Deep Reinforcement Learning, Lillicrap et al. 2016\n",
    "MorvanZhou's tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\n",
    "Environment\n",
    "-----------\n",
    "Openai Gym Pendulum-v0, continual action space\n",
    "\n",
    "Prerequisites\n",
    "-------------\n",
    "tensorflow >=2.0.0a0\n",
    "tensorflow-proactionsbility 0.6.0\n",
    "tensorlayer >=2.0.0\n",
    "\n",
    "To run\n",
    "------\n",
    "python tutorial_DDPG.py --train/test\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorlayer as tl\n",
    "\n",
    "# add arguments in command  --train/test\n",
    "# parser = argparse.ArgumentParser(description='Train or test neural net motor controller.')\n",
    "# parser.add_argument('--train', dest='train', action='store_true', default=False)\n",
    "# parser.add_argument('--test', dest='test', action='store_true', default=True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "#####################  hyper parameters  ####################\n",
    "\n",
    "ENV_ID = 'Pendulum-v1'  # environment id\n",
    "RANDOM_SEED = 2  # random seed, can be either an int number or None\n",
    "RENDER = False  # render while training\n",
    "\n",
    "ALG_NAME = 'DDPG'\n",
    "TRAIN_EPISODES = 100  # total number of episodes for training\n",
    "TEST_EPISODES = 10  # total number of episodes for training\n",
    "MAX_STEPS = 200  # total number of steps for each episode\n",
    "\n",
    "LR_A = 0.001  # learning rate for actor\n",
    "LR_C = 0.002  # learning rate for critic\n",
    "GAMMA = 0.9  # reward discount\n",
    "TAU = 0.01  # soft replacement\n",
    "MEMORY_CAPACITY = 10000  # size of replay buffer\n",
    "BATCH_SIZE = 32  # update action batch size\n",
    "VAR = 2  # control exploration\n",
    "\n",
    "###############################  DDPG  ####################################\n",
    "\n",
    "\n",
    "class DDPG(object):\n",
    "    \"\"\"\n",
    "    DDPG class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_dim, state_dim, action_range):\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, state_dim * 2 + action_dim + 1), dtype=np.float32)\n",
    "        self.pointer = 0\n",
    "        self.action_dim, self.state_dim, self.action_range = action_dim, state_dim, action_range\n",
    "        self.var = VAR\n",
    "\n",
    "        W_init = tf.random_normal_initializer(mean=0, stddev=0.3)\n",
    "        b_init = tf.constant_initializer(0.1)\n",
    "\n",
    "        def get_actor(input_state_shape, name=''):\n",
    "            \"\"\"\n",
    "            Build actor network\n",
    "            :param input_state_shape: state\n",
    "            :param name: name\n",
    "            :return: act\n",
    "            \"\"\"\n",
    "            input_layer = tl.layers.Input(input_state_shape, name='A_input')\n",
    "            layer = tl.layers.Dense(n_units=64, act=tf.nn.relu, W_init=W_init, b_init=b_init, name='A_l1')(input_layer)\n",
    "            layer = tl.layers.Dense(n_units=64, act=tf.nn.relu, W_init=W_init, b_init=b_init, name='A_l2')(layer)\n",
    "            layer = tl.layers.Dense(n_units=action_dim, act=tf.nn.tanh, W_init=W_init, b_init=b_init, name='A_a')(layer)\n",
    "            layer = tl.layers.Lambda(lambda x: action_range * x)(layer)\n",
    "            return tl.models.Model(inputs=input_layer, outputs=layer, name='Actor' + name)\n",
    "\n",
    "        def get_critic(input_state_shape, input_action_shape, name=''):\n",
    "            \"\"\"\n",
    "            Build critic network\n",
    "            :param input_state_shape: state\n",
    "            :param input_action_shape: act\n",
    "            :param name: name\n",
    "            :return: Q value Q(s,a)\n",
    "            \"\"\"\n",
    "            state_input = tl.layers.Input(input_state_shape, name='C_s_input')\n",
    "            action_input = tl.layers.Input(input_action_shape, name='C_a_input')\n",
    "            layer = tl.layers.Concat(1)([state_input, action_input])\n",
    "            layer = tl.layers.Dense(n_units=64, act=tf.nn.relu, W_init=W_init, b_init=b_init, name='C_l1')(layer)\n",
    "            layer = tl.layers.Dense(n_units=64, act=tf.nn.relu, W_init=W_init, b_init=b_init, name='C_l2')(layer)\n",
    "            layer = tl.layers.Dense(n_units=1, W_init=W_init, b_init=b_init, name='C_out')(layer)\n",
    "            return tl.models.Model(inputs=[state_input, action_input], outputs=layer, name='Critic' + name)\n",
    "\n",
    "        self.actor = get_actor([None, state_dim])\n",
    "        self.critic = get_critic([None, state_dim], [None, action_dim])\n",
    "        self.actor.train()\n",
    "        self.critic.train()\n",
    "\n",
    "        def copy_para(from_model, to_model):\n",
    "            \"\"\"\n",
    "            Copy parameters for soft updating\n",
    "            :param from_model: latest model\n",
    "            :param to_model: target model\n",
    "            :return: None\n",
    "            \"\"\"\n",
    "            for i, j in zip(from_model.trainable_weights, to_model.trainable_weights):\n",
    "                j.assign(i)\n",
    "\n",
    "        self.actor_target = get_actor([None, state_dim], name='_target')\n",
    "        copy_para(self.actor, self.actor_target)\n",
    "        self.actor_target.eval()\n",
    "\n",
    "        self.critic_target = get_critic([None, state_dim], [None, action_dim], name='_target')\n",
    "        copy_para(self.critic, self.critic_target)\n",
    "        self.critic_target.eval()\n",
    "\n",
    "        self.ema = tf.train.ExponentialMovingAverage(decay=1 - TAU)  # soft replacement\n",
    "\n",
    "        self.actor_opt = tf.optimizers.Adam(LR_A)\n",
    "        self.critic_opt = tf.optimizers.Adam(LR_C)\n",
    "\n",
    "    def ema_update(self):\n",
    "        \"\"\"\n",
    "        Soft updating by exponential smoothing\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        paras = self.actor.trainable_weights + self.critic.trainable_weights\n",
    "        self.ema.apply(paras)\n",
    "        for i, j in zip(self.actor_target.trainable_weights + self.critic_target.trainable_weights, paras):\n",
    "            i.assign(self.ema.average(j))\n",
    "\n",
    "    def get_action(self, s, greedy=False):\n",
    "        \"\"\"\n",
    "        Choose action\n",
    "        :param s: state\n",
    "        :param greedy: get action greedy or not\n",
    "        :return: act\n",
    "        \"\"\"\n",
    "        a = self.actor(np.array([s], dtype=np.float32))[0]\n",
    "        if greedy:\n",
    "            return a\n",
    "        return np.clip(\n",
    "            np.random.normal(a, self.var), -self.action_range, self.action_range\n",
    "        )  # add randomness to action selection for exploration\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Update parameters\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.var *= .9995\n",
    "        indices = np.random.choice(MEMORY_CAPACITY, size=BATCH_SIZE)\n",
    "        datas = self.memory[indices, :]\n",
    "        states = datas[:, :self.state_dim]\n",
    "        actions = datas[:, self.state_dim:self.state_dim + self.action_dim]\n",
    "        rewards = datas[:, -self.state_dim - 1:-self.state_dim]\n",
    "        states_ = datas[:, -self.state_dim:]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions_ = self.actor_target(states_)\n",
    "            q_ = self.critic_target([states_, actions_])\n",
    "            y = rewards + GAMMA * q_\n",
    "            q = self.critic([states, actions])\n",
    "            td_error = tf.losses.mean_squared_error(y, q)\n",
    "        critic_grads = tape.gradient(td_error, self.critic.trainable_weights)\n",
    "        self.critic_opt.apply_gradients(zip(critic_grads, self.critic.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            a = self.actor(states)\n",
    "            q = self.critic([states, a])\n",
    "            actor_loss = -tf.reduce_mean(q)  # maximize the q\n",
    "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_weights)\n",
    "        self.actor_opt.apply_gradients(zip(actor_grads, self.actor.trainable_weights))\n",
    "        self.ema_update()\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        \"\"\"\n",
    "        Store data in data buffer\n",
    "        :param s: state\n",
    "        :param a: act\n",
    "        :param r: reward\n",
    "        :param s_: next state\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        s = s.astype(np.float32)\n",
    "        s_ = s_.astype(np.float32)\n",
    "        transition = np.hstack((s, a, [r], s_))\n",
    "        index = self.pointer % MEMORY_CAPACITY  # replace the old memory with new memory\n",
    "        self.memory[index, :] = transition\n",
    "        self.pointer += 1\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        save trained weights\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        tl.files.save_weights_to_hdf5(os.path.join(path, 'actor.hdf5'), self.actor)\n",
    "        tl.files.save_weights_to_hdf5(os.path.join(path, 'actor_target.hdf5'), self.actor_target)\n",
    "        tl.files.save_weights_to_hdf5(os.path.join(path, 'critic.hdf5'), self.critic)\n",
    "        tl.files.save_weights_to_hdf5(os.path.join(path, 'critic_target.hdf5'), self.critic_target)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        load trained weights\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))\n",
    "        tl.files.load_hdf5_to_weights_in_order(os.path.join(path, 'actor.hdf5'), self.actor)\n",
    "        tl.files.load_hdf5_to_weights_in_order(os.path.join(path, 'actor_target.hdf5'), self.actor_target)\n",
    "        tl.files.load_hdf5_to_weights_in_order(os.path.join(path, 'critic.hdf5'), self.critic)\n",
    "        tl.files.load_hdf5_to_weights_in_order(os.path.join(path, 'critic_target.hdf5'), self.critic_target)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make(ENV_ID).unwrapped\n",
    "\n",
    "    # reproducible\n",
    "    # env.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    action_range = env.action_space.high  # scale action, [-action_range, action_range]\n",
    "\n",
    "    agent = DDPG(action_dim, state_dim, action_range)\n",
    "\n",
    "    t0 = time.time()\n",
    "    if True:  # train\n",
    "        all_episode_reward = []\n",
    "        for episode in range(TRAIN_EPISODES):\n",
    "            state, _ = env.reset()\n",
    "            episode_reward = 0\n",
    "            for step in range(MAX_STEPS):\n",
    "                if RENDER:\n",
    "                    env.render()\n",
    "                # Add exploration noise\n",
    "                action = agent.get_action(state)\n",
    "                state_, reward, done, info, _ = env.step(action)\n",
    "                agent.store_transition(state, action, reward, state_)\n",
    "\n",
    "                if agent.pointer > MEMORY_CAPACITY:\n",
    "                    agent.learn()\n",
    "\n",
    "                state = state_\n",
    "                episode_reward += reward\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if episode == 0:\n",
    "                all_episode_reward.append(episode_reward)\n",
    "            else:\n",
    "                all_episode_reward.append(all_episode_reward[-1] * 0.9 + episode_reward * 0.1)\n",
    "            print(\n",
    "                'Training  | Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'.format(\n",
    "                    episode + 1, TRAIN_EPISODES, episode_reward,\n",
    "                    time.time() - t0\n",
    "                )\n",
    "            )\n",
    "        agent.save()\n",
    "        plt.plot(all_episode_reward)\n",
    "        if not os.path.exists('image'):\n",
    "            os.makedirs('image')\n",
    "        plt.savefig(os.path.join('image', '_'.join([ALG_NAME, ENV_ID])))\n",
    "\n",
    "    if True:\n",
    "        # test\n",
    "        agent.load()\n",
    "        for episode in range(TEST_EPISODES):\n",
    "            state = env.reset()\n",
    "            episode_reward = 0\n",
    "            for step in range(MAX_STEPS):\n",
    "                env.render()\n",
    "                state, reward, done, info = env.step(agent.get_action(state, greedy=True))\n",
    "                episode_reward += reward\n",
    "                if done:\n",
    "                    break\n",
    "            print(\n",
    "                'Testing  | Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'.format(\n",
    "                    episode + 1, TEST_EPISODES, episode_reward,\n",
    "                    time.time() - t0\n",
    "                )\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
