%\section{انگیزه پژوهش}
%\section{انگیزه پژوهش}\label{sec:motivation}
%
%در دههٔ اخیر، گرایش روزافزون مأموریت‌های فضایی به استفاده از سامانه‌های سبک‌وزن و کم‌هزینه—از مدارگردهای زیردولتی گرفته تا صورت‌های متنوع ماهواره‌های مکعبی (CubeSat)—تقاضا برای روش‌های هدایت و کنترل خودکار و تضمین‌کنندهٔ امنیت مأموریت را به شکلی چشمگیر افزایش داده است. در این مأموریت‌ها، منابع پیشرانی محدود و محدودیت‌های توان پردازشی، هر دو، محیط طراحی را به سمت راهکارهایی سوق می‌دهند که ضمن بهینگی مصرف سوخت، نسبت به عدم‌قطعیت‌های «محیط سه‌جسمی محدود»ootnote{Circular Restricted Three‑Body Problem یا CRTBP} و آشفتگی‌های ناشی از خطاهای مدل و اختلالات بیرونی (مانند فشار تابشی خورشید و نامحوری جرم سیاره) مقاوم باشند.  
%
%از سوی دیگر، قرارگیری در نقطه‌های لاگرانژی \lr{\(L_1\)} و \lr{\(L_2\)} سامانهٔ خورشید–زمین، فرصت‌های اکتشافی بی‌سابقه‌ای—از رصد پس‌زمینهٔ کیهانی گرفته تا هواشناسی فضایی—فراهم کرده است، اما پایداری ذاتی پایین این نواحی، نیازمند راهبردهای ایمن نگه‌دارنده (station‑keeping) با دورهٔ کنترل کوتاه و واکنش سریع است. روش‌های کلاسیک همچون \lr{LQR} و هدایت بهینهٔ \lr{(OC)}, اگرچه در بسیاری از کاربردهای زمینی کارآمد بوده‌اند، در حضور سامانه‌های غیرخطی با ابعاد بالا و دینامیک آشوب‌گونهٔ CRTBP مستعد فروپاشی عملکرد (performance degradation) هستند؛ به ویژه زمانی که مدل دقیق جرم‌های آسمانی در دسترس نباشد یا حافظهٔ محاسباتی فضاپیما محدود شود.
%
%پیشرفت‌های اخیر در \lr{Machine Learning} و به طور خاص \lr{Reinforcement Learning (RL)}، چشم‌اندازی نو را پیش روی پژوهشگران سامانه‌های کنترلی قرار داده است؛ چراکه RL با یادگیری گام‌به‌گام از تعامل با محیط می‌تواند سیاست‌هایی را بیابد که نیازی به مدل صریح از دینامیک نداشته باشند. با این حال، اکثر کاربردهای موجود RL در حوزهٔ فضایی به صورت «تک‌عاملی» (Single‑Agent) و عمدتاً در چارچوب مسئله‌های \lr{Markov Decision Process (MDP)} صورت پذیرفته‌اند، حال آنکه تولد سامانه‌های مشارکتی و سناریوهای چندفازی (مانند مانورهای گله‌ای ماهواره‌ها یا مشارکت زمینی–مداری) مستلزم فریم‌ورک‌هایی چندعاملی است که بتواند برهم‌کنش‌های رقابتی–همکاری و همچنین نامعلومی‌های مشترک را مدیریت کند. الگوریتم‌های \lr{Multi‑Agent RL (MARL)}، به ویژه هنگامی که با تئوری بازی‌های دیفرانسیلی ترکیب شوند، قابلیتی فراهم می‌کنند تا عامل‌ها در برابر بدترین حالت اختلالات احتمالی (adversarial disturbances) آموزش ببینند و از آن طریق، ضریب اطمینان مأموریت ارتقا یابد.
%
%با وجود این پتانسیل، خلئی محسوس در ادبیات وجود دارد:  
%\begin{itemize}
%	\item \textbf{عدم تصریح چارچوبی جامع برای RL مقاوم در CRTBP} \cite{Naasz2022,Gabriel2023}؛ اکثر پژوهش‌ها یا به پایداری نقاط تعادل ساده اکتفا کرده یا تقارن کامل سامانه را فرض می‌کنند.
%	\item \textbf{نبود مقایسهٔ منصفانه بین الگوریتم‌های گرادیان‑سیاست (مانند TD3 و SAC) و روش‌های مبتنی بر توابع ارزش توزیعی} در سناریوهای فضایی گسسته–پیوسته.
%	\item \textbf{فقدان گزارش کمی از مزیت سوختی RL نسبت به کنترلرهای بهینهٔ کلاسیک}؛ آماری چون $\Delta m/m <1\%$ غالباً کیفی گزارش می‌شوند.
%\end{itemize}
%
%بر همین اساس، هدف از این پژوهش عبارت است از:  
%\begin{enumerate}
%	\item توسعهٔ یک چارچوب \textit{مقاوم} \lr{MARL}—بر پایهٔ بازی دیفرانسیلی صفرمجموع—برای مسئلهٔ هدایت کم‌پیشران در CRTBP، به نحوی که در برابر خطاهای مدل جرم اولیه و فشار تابشی تا $\pm20\,\%$ پایداری را حفظ کند.
%	\item طراحی یک تابع پاداش ترکیبی \(R=\alpha J_\text{fuel}+\beta J_\text{deviation}+\gamma J_\text{slack}\) که به طور هم‌زمان، مصرف سوخت و انحراف از مدار نامی را کمینه و محدودیت‌های پیشران را رعایت کند.
%	\item ارائهٔ مقایسهٔ جامع بین کنترلر پیشنهادی و رویکرد \lr{LQR/LQG}، از حیث $\Delta v$، تعداد اشتعال و خطای پسا‑ماموریت.
%\end{enumerate}
%
%تحقق این اهداف نه تنها می‌تواند سهم قابل‌توجهی در کاهش هزینه‌های مأموریت و افزایش عمر عملیاتی فضاپیماها داشته باشد، بلکه دانش طراحی کنترلی برای محیط‌های غیرخطی آشوبی را یک گام به افق «استقلال کامل تصمیم‌گیری در فضا» نزدیک‌تر می‌کند. به طور خاص، چارچوب ارائه شده قابلیت آن را دارد که در آینده به سادگی به سامانه‌های سه‌بعدی \lr{CR3BP} یا حتی دینامیک‌های چندجرمی تعمیم یابد، بدون آنکه نیاز به بازنویسی ساختار اصلی شبکهٔ عصبی باشد.
%
\section{انگیزه پژوهش}\label{sec:motivation}


%در دو دههٔ اخیر، چشم‌انداز مأموریت‌های فضایی به‌‌واسطهٔ کوچک‌سازی سامانه‌ها، پیشرفت الکترونیک ارزان‌قیمت و افزایش دسترس‌پذیری پرتابْ‌بارها، تغییر محسوسی را تجربه کرده است. از پروژه‌‌های علمی بین‌سیاره‌ای با محدودیت‌های منابع گرفته تا منظومه‌های پرشمارهٔ ماهواره‌ای در مدار زمین، همگی با چالش مشترکِ «هدایت بهینه در حضور عدم‌قطعیت» روبه‌رو هستند. در مسیرهای ترا-لونا و به‌طور خاص ناحیه‌های ناپایدار لاگرانژی در مدل «مسئلهٔ سه‌جسمی کروی محدود و دایروی» (CRTBP)، سامانهٔ کنترل باید قادر باشد با پیشران کم‌تراست (\emph{low‐thrust}) و underactuated، پایداری ایستا و کارایی مصرف سوخت را توأمان تضمین کند.  
%
%در عین حال، ظهور الگوریتم‌های یادگیری تقویتی عمیق (DRL) دریچهٔ تازه‌ای به‌سوی طراحی کنترلگرهای تطبیقی باز کرده است؛ ولی اغلب رویکردهای متداول بر سناریوهای تک‌عاملی و مدل‌های دقیق تکیه دارند. نبودِ استراتژی مقاوم در برابر اغتشاشات مدل و متغیرهای محیطی—از جمله خطای تراستِ موتورهای یونی و تأخیر حسگر—موجب می‌شود عملکرد در شرایط واقعی فاصلهٔ چشمگیری از نتایج شبیه‌سازی ایده‌آل پیدا کند. این پژوهش می‌کوشد شکاف مذکور را با استناد به چارچوب «یادگیری تقویتی چندعاملی مقاوم» پُر کرده و امکان هدایت کم‌سوخت در CRTBP را با وثوق عملیاتی ارتقا دهد.
%
%
%
%
%
%در دو دهه اخیر، چشم‌انداز مأموریت‌های فضایی به‌واسطهٔ کوچک‌سازی سامانه‌ها، پیشرفت الکترونیک ارزان‌قیمت، و افزایش دسترس‌پذیری پرتاب‌بارها، دگرگونی چشمگیری را تجربه کرده است. از پروژه‌های علمی بین‌سیاره‌ای با محدودیت‌های منابع گرفته تا منظومه‌های پرشمار ماهواره‌ای در مدار زمین، همگی با چالش مشترک «هدایت بهینه در حضور عدم‌قطعیت» روبه‌رو هستند. به‌ویژه در مسیرهای فرا-ماهی (ترا-لونا) و ناحیه‌های ناپایدار لاگرانژی در مدل «مسئلهٔ سه‌جسمی کروی محدود و دایروی» (CRTBP)، سامانه کنترل باید بتواند با پیشران کم‌تراست (low-thrust) و underactuated، پایداری ایستا و کارایی مصرف سوخت را توأمان تضمین کند.
%
%در همین حال، ظهور الگوریتم‌های یادگیری تقویتی عمیق (DRL)، افق‌های جدیدی را در طراحی کنترلگرهای تطبیقی گشوده است. با این وجود، اغلب رویکردهای متداول بر سناریوهای تک‌عاملی و مدل‌های دقیق متکی هستند. نبود یک استراتژی مقاوم در برابر اغتشاشات مدل و متغیرهای محیطی—مانند خطای تراست موتورهای یونی و تأخیر حسگر—باعث می‌شود که عملکرد در شرایط واقعی، فاصله چشمگیری از نتایج شبیه‌سازی ایده‌آل داشته باشد. این پژوهش می‌کوشد شکاف مذکور را با بهره‌گیری از چارچوب «یادگیری تقویتی چندعاملی مقاوم» پُر کرده و امکان هدایت کم‌سوخت در CRTBP را با اطمینان عملیاتی ارتقا دهد.

% "Translunar" refers to anything situated or traveling beyond the Moon or its orbit around Earth. It's commonly used in the context of spacecraft missions, particularly the translunar injection (TLI), which is a maneuver that puts a spacecraft on a trajectory towards the Moon. 
در دو دهه‌ی اخیر، ماموریت های فضایی به دلیل کوچک‌سازی سامانه ها، توسعه‌ی وسایل الکترونیک مقرون به صرفه و افزایش ظرفیت های پرتابی، تحولات بنیادینی را تجربه کرده است. از پروژه های علمی بین سیاره‌ایی گرفته تا منظومه های انبوه ماهواره‌ایی در مدارهای پایین زمین، همگی با چالش فراگیر هدایت بهینه در حضور عدم قطعیت های ذاتی مواجه‌اند. در مسیرهای فرا-قمری\LTRfootnote{Trans-lunar}
 و به طور خاص در ناحیه های ناپایدار نقاط لاگرانژ در چارچوب مسئله‌ی سه جسمی کروی محدود و دایروی\LTRfootnote{Circular Restricted Three-Body Problem (CRTBP)}، طراحی سامانه‌ی کنترل مستلزم توانایی تضمین همزمان پایداری ایستا و بهره‌وری سوخت با نیروی پیشران‌کم\LTRfootnote{Low-thrust}
 است.

هم‌راستا با این تحولات، ظهور و گسترش الگوریتم‌های یادگیری تقویتی عمیق\LTRfootnote{Deep Reinforcement Learning (DRL)}، امکانات نوینی را برای طراحی کنترل‌کننده‌های تطبیقی فراهم آورده است. با این حال، غالب رویکردهای رایج بر سناریوهای تک‌عاملی و اتکا به مدل‌های دینامیکی دقیق استوارند. غیاب یک استراتژی مقاوم در مواجهه با اغتشاشات مدل و تغییرات محیطی از جمله خطای تراست در پیشران‌ و تأخیر در سیگنال‌های حسگر منجر به فاصله‌ی چشمگیر عملکرد واقعی از پیش‌بینی‌های حاصل از شبیه‌سازی‌های ایده‌آل می‌گردد. این پژوهش بر آن است تا گسست اشاره‌شده را با بهره‌گیری از چارچوب یادگیری تقویتی چندعاملی مقاوم مرتفع سازد و بدین وسیله، اطمینان هدایت پیشران‌کم در \lr{CRTBP} را افزایش دهد.