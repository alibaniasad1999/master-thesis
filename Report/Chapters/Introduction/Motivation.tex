%\section{انگیزه پژوهش}
%\section{انگیزه پژوهش}\label{sec:motivation}
%
%در دهه‌ی اخیر، گرایش روزافزون مأموریت‌های فضایی به استفاده از سامانه‌های سبک‌وزن و کم‌هزینه—از مدارگردهای زیردولتی گرفته تا صورت‌های متنوع ماهواره‌های مکعبی (CubeSat)—تقاضا برای روش‌های هدایت و کنترل خودکار و تضمین‌کننده‌ی امنیت مأموریت را به شکلی چشمگیر افزایش داده است. در این مأموریت‌ها، منابع پیشرانی محدود و محدودیت‌های توان پردازشی، هر دو، محیط طراحی را به سمت راهکارهایی سوق می‌دهند که ضمن بهینگی مصرف سوخت، نسبت به عدم‌قطعیت‌های «محیط سه‌جسمی محدود»ootnote{Circular Restricted Three‑Body Problem یا CRTBP} و آشفتگی‌های ناشی از خطاهای مدل و اختلالات بیرونی (مانند فشار تابشی خورشید و نامحوری جرم سیاره) مقاوم باشند.  
%
%از سوی دیگر، قرارگیری در نقطه‌های لاگرانژی \lr{\(L_1\)} و \lr{\(L_2\)} سامانه‌ی خورشید–زمین، فرصت‌های اکتشافی بی‌سابقه‌ای—از رصد پس‌زمینه‌ی کیهانی گرفته تا هواشناسی فضایی—فراهم کرده است، اما پایداری ذاتی پایین این نواحی، نیازمند راهبردهای ایمن نگه‌دارنده (station‑keeping) با دوره‌ی کنترل کوتاه و واکنش سریع است. روش‌های کلاسیک همچون \lr{LQR} و هدایت بهینه‌ی \lr{(OC)}, اگرچه در بسیاری از کاربردهای زمینی کارآمد بوده‌اند، در حضور سامانه‌های غیرخطی با ابعاد بالا و دینامیک آشوب‌گونه‌ی CRTBP مستعد فروپاشی عملکرد (performance degradation) هستند؛ به ویژه زمانی که مدل دقیق جرم‌های آسمانی در دسترس نباشد یا حافظه‌ی محاسباتی فضاپیما محدود شود.
%
%پیشرفت‌های اخیر در \lr{Machine Learning} و به طور خاص \lr{Reinforcement Learning (RL)}، چشم‌اندازی نو را پیش روی پژوهشگران سامانه‌های کنترلی قرار داده است؛ چراکه RL با یادگیری گام‌به‌گام از تعامل با محیط می‌تواند سیاست‌هایی را بیابد که نیازی به مدل صریح از دینامیک نداشته باشند. با این حال، اکثر کاربردهای موجود RL در حوزه‌ی فضایی به صورت «تک‌عاملی» (Single‑Agent) و عمدتاً در چارچوب مسئله‌های \lr{Markov Decision Process (MDP)} صورت پذیرفته‌اند، حال آنکه تولد سامانه‌های مشارکتی و سناریوهای چندفازی (مانند مانورهای گله‌ای ماهواره‌ها یا مشارکت زمینی–مداری) مستلزم فریم‌ورک‌هایی چندعاملی است که بتواند برهم‌کنش‌های رقابتی–همکاری و همچنین نامعلومی‌های مشترک را مدیریت کند. الگوریتم‌های \lr{Multi‑Agent RL (MARL)}، به ویژه هنگامی که با تئوری بازی‌های دیفرانسیلی ترکیب شوند، قابلیتی فراهم می‌کنند تا عامل‌ها در برابر بدترین حالت اختلالات احتمالی (adversarial disturbances) آموزش ببینند و از آن طریق، ضریب اطمینان مأموریت ارتقا یابد.
%
%با وجود این پتانسیل، خلئی محسوس در ادبیات وجود دارد:  
%\begin{itemize}
%	\item \textbf{عدم تصریح چارچوبی جامع برای RL مقاوم در CRTBP} \cite{Naasz2022,Gabriel2023}؛ اکثر پژوهش‌ها یا به پایداری نقاط تعادل ساده اکتفا کرده یا تقارن کامل سامانه را فرض می‌کنند.
%	\item \textbf{نبود مقایسه‌ی منصفانه بین الگوریتم‌های گرادیان‑سیاست (مانند TD3 و SAC) و روش‌های مبتنی بر توابع ارزش توزیعی} در سناریوهای فضایی گسسته–پیوسته.
%	\item \textbf{فقدان گزارش کمی از مزیت سوختی RL نسبت به کنترلرهای بهینه‌ی کلاسیک}؛ آماری چون $\Delta m/m <1\%$ غالباً کیفی گزارش می‌شوند.
%\end{itemize}
%
%بر همین اساس، هدف از این پژوهش عبارت است از:  
%\begin{enumerate}
%	\item توسعه‌ی یک چارچوب \textit{مقاوم} \lr{MARL}—بر پایه‌ی بازی دیفرانسیلی صفرمجموع—برای مسئله‌ی هدایت کم‌پیشران در CRTBP، به نحوی که در برابر خطاهای مدل جرم اولیه و فشار تابشی تا $\pm20\,\%$ پایداری را حفظ کند.
%	\item طراحی یک تابع پاداش ترکیبی \(R=\alpha J_\text{fuel}+\beta J_\text{deviation}+\gamma J_\text{slack}\) که به طور هم‌زمان، مصرف سوخت و انحراف از مدار نامی را کمینه و محدودیت‌های پیشران را رعایت کند.
%	\item ارائه‌ی مقایسه‌ی جامع بین کنترلر پیشنهادی و رویکرد \lr{LQR/LQG}، از حیث $\Delta v$، تعداد اشتعال و خطای پسا‑ماموریت.
%\end{enumerate}
%
%تحقق این اهداف نه تنها می‌تواند سهم قابل‌توجهی در کاهش هزینه‌های مأموریت و افزایش عمر عملیاتی فضاپیماها داشته باشد، بلکه دانش طراحی کنترلی برای محیط‌های غیرخطی آشوبی را یک گام به افق «استقلال کامل تصمیم‌گیری در فضا» نزدیک‌تر می‌کند. به طور خاص، چارچوب ارائه شده قابلیت آن را دارد که در آینده به سادگی به سامانه‌های سه‌بعدی \lr{CR3BP} یا حتی دینامیک‌های چندجرمی تعمیم یابد، بدون آنکه نیاز به بازنویسی ساختار اصلی شبکه‌ی عصبی باشد.
%
\section{انگیزه پژوهش}\label{sec:motivation}

در دو دهه‌ی اخیر، به‌دلیل کوچک‌سازی سامانه‌ها، توسعه‌ی الکترونیک مقرون‌به‌صرفه و افزایش ظرفیت‌های پرتاب، تحولات بنیادینی در مأموریت‌های فضایی تجربه شده‌است. از پروژه‌های علمیِ بین‌سیاره‌ای تا منظومه‌های انبوه ماهواره‌ای در مدارهای پایین زمین، مواجهه با چالشِ فراگیرِ هدایتِ بهینه در حضور عدم‌قطعیت‌ها به‌طور گسترده گزارش شده‌است. در مسیرهای فرا-قمری\LTRfootnote{Trans-lunar}
و به‌طور خاص در ناحیه‌های ناپایدارِ نقاط لاگرانژ در چارچوب مسئله‌ی سه‌جسمیِ کرویِ محدودِ دایروی\LTRfootnote{Circular Restricted Three-Body Problem (CRTBP)}، طراحی سامانه‌ی کنترل مستلزم تضمین هم‌زمانِ پایداریِ ایستا و بهره‌وریِ سوخت با پیشران‌کم\LTRfootnote{Low-thrust} است.

هم‌راستا با این تحولات، ظهور و گسترشِ الگوریتم‌های یادگیری تقویتیِ عمیق\LTRfootnote{Deep Reinforcement Learning (DRL)} امکانات نوینی برای طراحیِ کنترل‌کننده‌های تطبیقی فراهم آورده است؛ با این حال، غالبِ رویکردهای رایج بر سناریوهای تک‌عاملی و اتکا به مدل‌های دینامیکیِ دقیق استوار شده‌اند. غیابِ یک راهبردِ مقاوم در برابر اغتشاشاتِ مدل و تغییرات محیطی—از جمله خطای تراستِ پیشران و تأخیر حسگر—به ایجادِ فاصله‌ی معنادار میان عملکرد واقعی و پیش‌بینی‌های شبیه‌سازیِ ایده‌آل منجر شده‌است. در این پژوهش، این شکاف با بهره‌گیری از چارچوبِ یادگیریِ تقویتیِ چندعاملیِ مقاوم پُر می‌شود و اطمینانِ هدایتِ پیشران‌کم در \lr{CRTBP} ارتقا داده می‌شود. در ادامه، تعریف دقیق مسئله و سپس اهداف و نوآوری‌های پژوهش ارائه می‌شود.
