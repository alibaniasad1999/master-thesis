	\section{طراحی عامل}\label{sec:agent_design}

در این زیربخش، معماری عامل هوشمند کنترل‌کننده فضاپیما در محیط سه‌جسمی شرح داده شده است. این معماری شامل تعریف فضای حالت، عمل و تابع پاداش است.


\subsection{ فضای حالت}

فضای حالت\LTRfootnote{State Space}
در این پژوهش به‌گونه‌ای طراحی شده است که وضعیت دینامیکی فضاپیما را نسبت به یک مسیر و سرعت مرجع مشخص می‌کند. این فضا شامل اختلاف‌های موقعیت و سرعت از مسیر و سرعت مرجع  است و به‌صورت زیر تعریف شده است:
\[
S = \{ \delta x, \delta y, \delta \dot{x}, \delta \dot{y} \}
\]

که در آن:
\begin{itemize}
	\item \( \delta x, \delta y \): اختلاف موقعیت فضاپیما نسبت به مسیر مرجع در محورهای \( x, y \) .
	\item \( \delta \dot{x}, \delta \dot{y} \): اختلاف سرعت فضاپیما نسبت به سرعت مرجع در محورهای \( x, y \) .
\end{itemize}

هر یک از این متغیرها به‌طور مستقل وضعیت فضاپیما را در یک جهت خاص توصیف می‌کنند و امکان تحلیل دقیق انحرافات را فراهم می‌سازند.
%\subsection{دلیل انتخاب اختلاف‌ها به‌عنوان متغیرهای فضای حالت}
استفاده از اختلاف‌های موقعیت و سرعت به جای مقادیر مطلق، به دلایل زیر انجام شده است:
\begin{itemize}
	\item \textbf{تمرکز بر انحرافات}: هدف اصلی سیستم کنترلی، کاهش انحرافات از مسیر و سرعت مطلوب است. با استفاده از اختلاف‌ها، کنترلر می‌تواند به طور مستقیم بر این انحرافات اثر بگذارد و نیازی به محاسبه مقادیر مطلق موقعیت و سرعت ندارد.
	%    \item \textbf{سادگی در طراحی کنترلر}: تعریف فضای حالت بر اساس اختلاف‌ها، معادلات دینامیکی را ساده‌تر می‌کند و طراحی کنترلرهای خطی یا غیرخطی را تسهیل می‌نماید.
	%    \item \textbf{بهینه‌سازی محاسبات}: از آنجایی که مسیر و سرعت مرجع معمولاً ثابت یا از پیش تعیین‌شده هستند، محاسبه اختلاف‌ها به جای مقادیر مطلق، حجم محاسبات را کاهش می‌دهد و دقت شبیه‌سازی را افزایش می‌دهد.
	\item \textbf{سازگاری با یادگیری تقویتی}: در الگوریتم‌های یادگیری تقویتی، فضاهای حالت مبتنی بر اختلاف معمولاً دامنه محدودتری دارند که فرآیند یادگیری را سریع‌تر و پایدارتر می‌کند.
\end{itemize}


\subsection{فضای عمل }



فضای عمل\LTRfootnote{Action Space} 
فضاپیما با پیشران‌کم
مجموعه‌ای از عمل‌های پیوسته است که فضاپیما می‌تواند در محیط شبیه‌سازی انجام دهد. این فضا به‌گونه‌ای طراحی شده که امکان اعمال نیرو در جهت‌های مشخص و با مقادیر متناسب با توان واقعی فضاپیماها فراهم شود. به‌طور خاص، فضای اقدام شامل موارد زیر است:

\begin{itemize}
	\item \textbf{نیروی اعمال‌شده در جهت \( x \)}: این متغیر پیوسته، مقدار نیرویی را که در جهت محور \( x \) به فضاپیما وارد می‌شود، تعیین می‌کند. دامنه این نیرو بر اساس توان پیشرانه‌های موجود در فضاپیماهای واقعی انتخاب شده است. به عبارت دیگر، اگر حداکثر نیروی قابل اعمال در جهت \( x \) برابر با \( f_{x,\max} \) باشد، این متغیر می‌تواند مقادیری در بازه \( [-f_{x,\max}, f_{x,\max}] \) داشته باشد.
	
	\item \textbf{نیروی اعمال‌شده در جهت \( y \)}: این متغیر پیوسته، مقدار نیرویی را که در جهت محور \( y \) به فضاپیما وارد می‌شود، مشخص می‌کند. مشابه جهت \( x \)، دامنه این نیرو نیز بر اساس توان پیشرانه‌های موجود تعیین شده و می‌تواند در بازه \( [-f_{y,\max}, f_{y,\max}] \) قرار گیرد.
\end{itemize}

انتخاب این نیروها بر اساس ویژگی‌های واقعی فضاپیماها، به‌ویژه توان و محدودیت‌های پیشرانه‌های آن‌ها، صورت گرفته است. این امر اطمینان می‌دهد که شبیه‌سازی تا حد ممکن به شرایط واقعی نزدیک باشد و نتایج به‌دست‌آمده قابلیت تعمیم به کاربردهای عملی را داشته باشند. همچنین، تعریف فضای اقدام به‌صورت پیوسته، امکان کنترل دقیق و انعطاف‌پذیر بر حرکت فضاپیما را فراهم می‌کند، که برای دستیابی به اهداف کنترلی در محیط‌های دینامیکی پیچیده ضروری است.
به‌طور خلاصه، فضای اقدام به‌صورت زیر تعریف می‌شود:
\[
a = \{ f_x, f_y \mid f_x \in [-f_{x,\max}, f_{x,\max}], \, f_y \in [-f_{y,\max}, f_{y,\max}] \}
\]

% --- افزودنی: جدول ماهواره‌های مشابه و ارتباط با بازه‌ی فضای عمل ---
\subsubsection*{انطباق بازه‌ی فضای عمل با داده‌های واقعی}
برای هم‌تراز کردن شبیه‌سازی با سخت‌افزارهای واقعی، از بیشینه‌ی نیروی بی‌بُعدِ پیشران‌ها استفاده می‌شود. جدول زیر نمونه‌هایی از فضاپیماهای مجهز به پیشران‌های یونی/الکتریکی را نشان می‌دهد که مبنای انتخاب بازه‌ی نیروی عمل قرار گرفته شده‌اند. با توجه به برداری‌بودن عمل
$\boldsymbol{a}=[
f_x ~  f_y
]$،
کران‌ها را به دو صورت اعمال شده است:
\[
|a| \le f_{\text{max, nondim}}
\quad \text{یا} \quad
f_{x,\max}=f_{y,\max}=f_{\text{max, nondim}}.
\]
با استناد به جدول
\ref{tab:camparison}،
مقدار نمونه‌ی \(4{\times}10^{-2}\) شبیه‌سازی شده با \lr{Psyche} هم‌مرتبه و کمتر از \lr{DS1} است که باعث شده‌است بازه‌ی عمل را در چارچوب پیشران‌های کم‌تراست واقع‌گرایانه نگه داشته شود.


\vspace{1cm}
\begin{table*}[h!]
	\centering
	\begin{RTL}
		\caption{قابلیت‌های بی‌بعد پیشران‌کم‌تراستِ {فضاپیماهای} مختلف در سامانه‌ی زمین–ماه \cite{lafarge}.}
		\label{tab:camparison}
		\begin{tabular}{|l|l|l|l|l|}
			\hline
			{\textbf{نام اختصار}} & {\textbf{نام فضاپیما}} & \lr{\textbf{$f_{\text{max, nondim}}$}} & \lr{\textbf{$M_{3,0}$ (kg)}} & \lr{\textbf{$F_{\text{max}}$ (mN‌)}} \\ \hline
			\lr{DS1} & \lr{Deep Space 1} & $6.940 \cdot 10^{-2}$ & $486.3$ & $92.0$ \\ \hline
			\lr{Psyche} & \lr{Psyche} & $4.158 \cdot 10^{-2}$ & $2464$ & $279.3$ \\ \hline
			\lr{Dawn} & \lr{Dawn}  & $2.741 \cdot 10^{-2}$ & $1217.8$ & $91.0$ \\ \hline
			\lr{LIC} & \lr{Lunar IceCube} & $3.276 \cdot 10^{-2}$ & $14$ & $1.25$ \\ \hline
			\lr{H1} & \lr{Hayabusa 1} & $1.640 \cdot 10^{-2}$ & $510$ & $22.8$ \\ \hline
			\lr{H2} & \lr{Hayabusa 2} & $1.628 \cdot 10^{-2}$ & $608.6$ & $27.0$ \\ \hline
			\lr{s/c} & فضاپیمای نمونه & $4 \cdot 10^{-2}$ & $-$ & $-$ \\ \hline
		\end{tabular}
	\end{RTL}
\end{table*}


% --- پایان افزودنی ---





\subsection{تابع پاداش}
تابع پاداش\LTRfootnote{Reward Function}
به‌منظور هدایت رفتار عامل طراحی شده و شامل سه بخش اصلی در طول شبیه‌سازی و یک پاداش نهایی در هنگام پایان است:
\begin{itemize}
	\item \textbf{پاداش نهایی برای دستیابی به هدف}: در صورت رسیدن به مدار هدف، شبیه‌سازی پایان یافته و یک پاداش بزرگ مثبت به عامل داده می‌شود.
	\item \textbf{جریمه نهایی برای دور شدن بیش‌از‌حد}: اگر عامل از محدوده مجاز فاصله بگیرد، شبیه‌سازی خاتمه یافته و یک جریمه بزرگ منفی اعمال می‌گردد.
	\item \textbf{جریمه برای مصرف سوخت}: در طول مسیر، استفاده بیش‌از‌حد از پیشرانه با جریمه همراه است.
	\item \textbf{جریمه برای انحراف از مسیر مرجع}: در طول مسیر، انحراف از مسیر مرجع باعث دریافت جریمه متناسب می‌شود.
\end{itemize}

تابع پاداش به‌صورت زیر تعریف می‌شود:
\[
r(s, a) = r_{\text{thrust}}(a) + r_{\text{reference}}(s) + r_{\text{terminal}}(s)
\]

که در آن مؤلفه‌ها عبارتند از:
\begin{align}
	r_{\text{thrust}}(a) &= -k_1 \cdot |a| \\
	r_{\text{reference}}(s) &= -k_2 \cdot d(s, s_{\text{reference}}) \\
	r_{\text{terminal}}(s) &= 
	\begin{cases}
		+R_{\text{goal}} & \text{if} ~ s \in S_{\text{goal}} \\
		-R_{\text{fail}} & \text{if} ~ d(s, s_{\text{reference}}) > \epsilon \\
		0 & \text{otherwise}
	\end{cases}
\end{align}

در این رابطه:  
\begin{enumerate}
	\item \(R_{\text{goal}}\): یک پاداش بزرگ مثبت برای دستیابی به هدف است.
	\item \(R_{\text{fail}}\): یک جریمه بزرگ منفی برای خروج از محدوده مجاز است.
	\item \(d(s, s')\): فاصله بین دو وضعیت بوده و معمولاً به‌صورت فاصله اقلیدسی محاسبه می‌شود.
\end{enumerate}


ضرایب \(k_1, k_2\) برای تنظیم تعادل بین بهینه‌سازی مصرف سوخت و حفظ نزدیکی به مسیر مرجع استفاده می‌شوند. انتخاب مناسب مقادیر این ضرایب نقش کلیدی در سرعت همگرایی و پایداری الگوریتم یادگیری تقویتی دارد.  







