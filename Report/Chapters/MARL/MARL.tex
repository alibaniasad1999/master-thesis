\chapter{یادگیری تقویتی چندعاملی}
کاربردهای پیچیده در یادگیری تقویتی نیازمند اضافه کردن چندین عامل\LTRfootnote{Multi-Agent} برای انجام همزمان وظایف مختلف هستند.
با این حال، افزایش تعداد عامل‌ها چالش‌هایی در مدیریت تعاملات میان آن‌ها به همراه دارد.
در این فصل، بر اساس مسئله بهینه‌سازی برای هر عامل، مفهوم تعادل\LTRfootnote{Equilibrium} معرفی شده تا رفتارهای توزیعی چندعاملی را تنظیم کند.
رابطه رقابت میان عامل‌ها در سناریوهای مختلف تحلیل شده و آن‌ها با الگوریتم‌های معمول یادگیری تقویتی چندعاملی ترکیب شده‌اند. بر اساس انواع تعاملات، یک چارچوب نظریه بازی برای مدل‌سازی عمومی در سناریوهای چندعاملی استفاده شده است. با تحلیل بهینه‌سازی و وضعیت تعادل برای هر بخش از چارچوب، سیاست بهینه یادگیری تقویتی چندعاملی برای هر عامل بررسی شده است.




  \input{Chapters/MARL/def}
  % \input{Chapters/MARL/MARL_importance}
    \input{Chapters/MARL/games}
    \input{Chapters/MARL/nash}
    \input{Chapters/MARL/zero_sum}
    \input{Chapters/MARL/MADDPG}
    \input{Chapters/MARL/MATD3}
    \input{Chapters/MARL/MASAC}
     \input{Chapters/MARL/MAPPO}
%    \input{Chapters/MARL/safe}
%    \input{Chapters/MARL/algorithms}
       \section{تنظیمات آزمایشی}
    \section{نتایج عملکرد الگوریتم‌ها}
    \section{تحلیل پایداری و همگرایی}
    \section{مقایسه روش‌های تک‌عاملی و چندعاملی}
    \section{ارزیابی مقاومت الگوریتم‌ها در برابر اختلالات}
    \section{تحلیل آماری نتایج}
    \section{بحث و تفسیر نتایج}
    \section{مقایسه با معیارهای مرجع}
    \section{جمع‌بندی و پیشنهادات آتی} 