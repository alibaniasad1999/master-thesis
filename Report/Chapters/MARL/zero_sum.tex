%\subsection{بازی مجموع صفر}
%
%بازی‌های مجموع صفر\LTRfootnote{Zero-Sum Games}
% دسته‌ای از بازی‌ها هستند که در آن‌ها تابع ارزش یک بازیکن دقیقاً برابر با ضرر بازیکن دیگر است. به عبارت دیگر، مجموع ارزشهای همه بازیکنان در هر مرحله صفر است.
%
%
%
%\begin{itemize}
%	\item تعریف بازی مجموع صفر:
%	در یک بازی دو نفره، اگر تابع ارزش بازیکن اول (\( V_1^{(\pi_1 ,\pi_2)}(s)
%	\)) و بازیکن دوم (\( V_2^{(\pi_1 ,\pi_2)}(s)
%	\)) به‌گونه‌ای باشد که برای هر مجموعه سیاست
%	\( (\pi_1, \pi_2) \) 
%به صورت زیر باشد را یک بازی مجموع صفر نامیده می‌شود.
%	\begin{equation}\label{eq:game_v}
%		V_1^{(\pi_1 ,\pi_2)}(s) + V_2^{(\pi_1 ,\pi_2)}(s) = 0 \to V_1^{(\pi_1 ,\pi_2)}(s) = -V_2^{(\pi_1 ,\pi_2)}(s)
%%		V_1^{(\pi_1 ,\pi_2)}(s) =- V_2^{(\pi_1, \pi_2)}(s)
%	\end{equation}
%	\item سیاست بهینه در بازی مجموع صفر:
%	در بازی‌های مجموع صفر، سیاست بهینه هر بازیکن، انتخابی است که  تابع ارزش خود را در برابر بهترین پاسخ حریف به حداکثر برساند. این سیاست اغلب به تعادل نش منجر می‌شود. سیاست بهینه دو بازیکن در بازی مجموع صفر با تابع  ارزش معادله
%	\eqref{eq:game_v}
%	به صورت زیر است.
%	
%	\begin{align}
%		V_1^*(s) = \max_{\pi_1} \min_{\pi_2} V_1^{(\pi_1 ,\pi_2)}(s) \\
%		V_2^*(s) = \max_{\pi_2} \min_{\pi_1} V_2^{(\pi_1 ,\pi_2)}(s)
%	\end{align}
%	
%	
%\end{itemize}


















\subsection{بازی مجموع صفر}

بازی‌های مجموع صفر\LTRfootnote{Zero-Sum Games}
دسته‌ای از بازی‌ها هستند که در آن‌ها تابع ارزش یک بازیکن دقیقاً برابر با ضرر بازیکن دیگر است؛ ازاین‌رو، مجموع ارزش‌های همه‌ی بازیکنان در هر وضعیت صفر خواهد بود.

\begin{itemize}
	%------------------------------------
	\item \textbf{تعریف بازی مجموع صفر:}
	
	در یک بازی دو نفره، اگر تابع ارزشِ حالت (value) بازیکن اوّل 
	\(V_1^{(\pi_1 ,\pi_2)}(s)\)
	و بازیکن دوم 
	\(V_2^{(\pi_1 ,\pi_2)}(s)\)
	برای هر مجموعه سیاست 
	\((\pi_1,\pi_2)\)
	به‌گونه‌ای باشند که:
	\begin{equation}\label{eq:game_v}
		V_1^{(\pi_1 ,\pi_2)}(s) + V_2^{(\pi_1 ,\pi_2)}(s) = 0 
		\;\;\Longrightarrow\;\;
		V_1^{(\pi_1 ,\pi_2)}(s) = -\,V_2^{(\pi_1 ,\pi_2)}(s),
	\end{equation}
	آنگاه آن بازی را {بازی مجموع صفر} می‌نامیم.
	
	به‌طور مشابه، اگر تابع ارزش–عمل برای دو بازیکن را با
	\(Q_1^{(\pi_1,\pi_2)}(s,a_1,a_2)\)
	و
	\(Q_2^{(\pi_1,\pi_2)}(s,a_1,a_2)\)
	نشان دهیم، باید برقرار باشد:
	\begin{equation}\label{eq:game_q}
		Q_1^{(\pi_1,\pi_2)}(s,a_1,a_2) + 
		Q_2^{(\pi_1,\pi_2)}(s,a_1,a_2) = 0
		\;\;\Longrightarrow\;\;
		Q_1^{(\pi_1,\pi_2)}(s,a_1,a_2) = -\,Q_2^{(\pi_1,\pi_2)}(s,a_1,a_2).
	\end{equation}
	%------------------------------------
	
	\item \textbf{سیاست بهینه در بازی مجموع صفر:}
	
	در این بازی‌ها، هر بازیکن سیاستی را برمی‌گزیند که تابع ارزش خود را
	در برابر بهترین پاسخِ حریف بیشینه کند؛ این انتخاب در نهایت به
	تعادل نش منجر می‌شود.
	
	به‌صورت تابع ارزشِ حالت:
	\begin{align}
		V_1^*(s) &= \max_{\pi_1}\,\min_{\pi_2} \;
		V_1^{(\pi_1 ,\pi_2)}(s), \\
		V_2^*(s) &= \max_{\pi_2}\,\min_{\pi_1} \;
		V_2^{(\pi_1 ,\pi_2)}(s).
	\end{align}
	
	و به‌صورت تابع ارزش–عمل:
	\begin{align}
		Q_1^*(s,a_1,a_2) &= \max_{\pi_1}\,\min_{\pi_2} \;
		Q_1^{(\pi_1 ,\pi_2)}(s,a_1,a_2), \\
		Q_2^*(s,a_1,a_2) &= \max_{\pi_2}\,\min_{\pi_1} \;
		Q_2^{(\pi_1 ,\pi_2)}(s,a_1,a_2).
	\end{align}
	\item \textbf{تابع پاداش:}
	تابع پاداش
	در بازی‌های دوسویه مجموع‌صفر باید به‌گونه‌ای طراحی شود که پاداش لحظه‌ای دو عامل در هر گام جمعاً صفر باشد. در ادامه ساختار پاداش عاملِ ۱ مشابه قالب تک‌عاملی تعریف می‌شود و پاداش عاملِ ۲ به‌صورت منفی آن اخذ می‌گردد.
	
	\begin{itemize}
		\item \textbf{پاداش نهایی برای دستیابی به هدفِ عامل ۱}: در صورت رسیدن به هدف عامل ۱، شبیه‌سازی پایان یافته و پاداش بزرگ مثبت به او داده می‌شود.
		\item \textbf{جریمه نهایی برای دور شدنِ عامل ۱}: اگر عامل ۱ از محدوده مجاز خود خارج شود، شبیه‌سازی خاتمه یافته و جریمه بزرگ منفی اعمال می‌گردد.
		\item \textbf{جریمه برای مصرف سوختِ عامل ۱}: استفاده بیش‌از‌حد از پیشرانه برای عامل ۱ با جریمه همراه است.
		\item \textbf{جریمه برای انحراف از مسیر مرجعِ عامل ۱}: انحراف از مسیر مرجع عامل ۱ باعث دریافت جریمه متناسب می‌شود.
	\end{itemize}
	
	تابع پاداش عامل ۱ به‌صورت زیر تعریف می‌شود:
	\[
	r_1(s, a_1, a_2) = r_{\text{thrust},1}(a_1) + r_{\text{thrust},1}(a_2) + r_{\text{reference},1}(s) + r_{\text{terminal},1}(s)
	\]
	
	که در آن مؤلفه‌ها عبارتند از:
	\begin{align}
		r_{\text{thrust},1}(a_1) &= -k_1 \cdot |a_1| \\
		r_{\text{thrust},1}(a_2) &= -k_2 \cdot |a_2| \\
		r_{\text{reference},1}(s) &= -k_3 \cdot d_1\!\big(s, s_{\text{ref},1}\big) \\
		r_{\text{terminal},1}(s) &=
		\begin{cases}
			+R_{\text{goal},1} & \text{if}~ s \in S_{\text{goal},1} \\
			-R_{\text{fail},1} & \text{if}~ d_1\!\big(s, s_{\text{ref},1}\big) > \epsilon_1 \\
			0 & \text{otherwise}
		\end{cases}
	\end{align}
	
	برای تضمین خاصیت مجموع‌صفر، پاداشِ عامل ۲ را در هر گام به‌صورت زیر تعریف می‌کنیم:
	\[
	r_2(s, a_1, a_2) = -\,r_1(s, a_1, a_2),
	\]
	بنابراین با افق و ضریب تنزیل یکسان، روابط \eqref{eq:game_v} و \eqref{eq:game_q} نیز برقرار خواهند بود.
	
	در این رابطه:
	\begin{enumerate}
		\item \(R_{\text{goal},1}\): پاداش بزرگ مثبت برای دستیابی عامل ۱ به هدف.
		\item \(R_{\text{fail},1}\): جریمه بزرگ منفی برای خروج عامل ۱ از محدوده مجاز.
		\item \(d_1(s, s')\): فاصله مرتبط با عامل ۱ اقلیدسی بین دو وضعیت.
	\end{enumerate}
	
	ضرایب \(k_1, k_2, k_3\) برای تنظیم تعادل بین جریمهٔ پیشرانهٔ عامل ۱، جریمهٔ پیشرانهٔ عامل ۲، و جریمهٔ انحراف از مسیر مرجع استفاده می‌شوند. به‌دلیل تعریف \(r_2=-r_1\)، جمع پاداش‌ها در هر گام صفر بوده و مقدار بازی یکتا و با تعادل نش در راهبردهای مختلط سازگار است.
	
	
	
\end{itemize}

% نکته‌ی وجود تعادل در بازی‌های متناهیِ مجموع‌صفر:
بر پایه‌ی قضیه‌ی کمینه‌بیشینه‌ی فون‌نویمان، در بازی‌های دوسویه‌ی مجموع‌صفرِ متناهی داریم:
\[
\max_{\pi_1}\min_{\pi_2} V_1^{(\pi_1,\pi_2)}(s)
=
\min_{\pi_2}\max_{\pi_1} V_1^{(\pi_1,\pi_2)}(s),
\]
که وجود تعادل نش در راهبردهای مختلط و یکتایی مقدار بازی را تضمین می‌کند.

%\subsection{تابع پاداش} \label{subsec:marl_reward}
