%\section{یادگیری تقویتی چندعاملی}
\section{پیشینه‌ی پژوهش یادگیری تقویتی چندعاملی}\label{sec:marl_lit}

امروز یادگیری تقویتی چندعاملی\LTRfootnote{Multi-Agent Reinforcement Learning (MARL)} به‌عنوان بنیاد اصلی سامانه‌های هوشمند مشارکتی شناخته می‌شود؛ مسیری که از آزمون‌های ساده‌ی دو‌عاملی در دهه‌ی ۱۹۹۰ آغاز شد و اکنون به معماری‌های توزیع‌شده‌ی در مقیاس هزاران بازیگر رسیده است. این بخش، به بررسی اینکه چگونه ایده‌ی {آموزش متمرکز ـ اجرای توزیع‌شده} (\lr{CTDE}) به پاسخ غالب برای چالش‌های غیرایستایی و انفجار بُعدی\LTRfootnote{Curse of Dimensionality}
 بدل شد و چه گام‌هایی هنوز برای ایمنی، ناهمگونی و مقیاس‌پذیری باقی مانده است.

دهه‌ی ۱۹۹۰ با مقاله‌ی \cite{Tan1993} آغاز شد؛ جایی که برای نخستین‌بار مقایسه‌ی عامل‌های مستقل با عامل‌های همکار انجام شد و سود ارتباط و اشتراک تجربه به‌صورت تجربی نشان داده شد. در میانه‌ی دهه‌ی بعد، مرور جامع پانایت و لوک \cite{Panait2005} چشم‌اندازی از مسائل تخصیص اعتبار و غیرایستایی ترسیم کرد و دو موضوع یادگیری تیمی و یادگیری هم‌زمان را صورت‌بندی نمود.  هم‌زمان، بوشونیـو و همکاران \cite{Busoniu2008} ادبیات \lr{MARL} را در قالب اهداف پایداری دینامیک یادگیری و انطباق با رفتار سایر عامل‌ها جمع‌بندی کردند و راه را برای تحلیل‌های بازی‌محور هموار ساختند. 

ورود شبکه‌های عمیق در سال‌های ۲۰۱۶ و ۲۰۱۷ نقطه‌ی عطف بعدی بود؛ منتقد متمرکز ـ بازیگر توزیع‌شده در \lr{MA-DDPG} \cite{Lowe2017} نشان داد که می‌توان از حالت سراسری در فاز آموزش بهره برد، اما سیاست نهایی را صرفاً بر اساس مشاهدات محلی اجرا کرد.  در همان سال، \lr{Value‐Decomposition Networks}
\cite{Sunehag2017} ایده‌ی تجزیه‌ی خطی پاداش را برای همکاری عامل‌ها مطرح کرد و راه را برای تقسیم بندی‌های پیش‌رفته پاداش گشود. 

۲۰۱۸ شاهد جهش مهمی با \lr{QMIX} بود؛ این روش با اعمال قید تک‌نوا\LTRfootnote{Monotonic}
 بر ترکیب مقادیر منفرد، هم امکان بهینه‌سازی غیرسیاست‌محور را فراهم کرد و هم تضمین سازگاری سیاست‌های محلی با ارزش مشترک را برقرار ساخت \cite{Rashid2018}. 

سال ۲۰۱۹ به گسترش بسترهای آزمایش اختصاص یافت. چالش استاندارد
 \lr{StarCraft Multi-Agent Challenge (SMAC)} بر مبنای \lr{StarCraft II} معرفی شد و معیار مشترکی برای مقایسه‌ی الگوریتم‌ها را مهیا کرد
  \cite{Samvelyan2019SMAC}.
  هم‌زمان، \lr{QTRAN} \cite{Son2019QTRAN} نشان داد که می‌توان بدون قید خطی یا تک‌نوا، تابع ارزش مشترک را به فضای قابل تجزیه تبدیل کرد. از سوی دیگر، \lr{MAVEN} با افزودن متغیر نهفته‌ی مشترک، کاوش هماهنگ و سلسله‌مراتبی را امکان‌پذیر ساخت \cite{Mahajan2019MAVEN}.  نقطه‌ی اوج همان سال، سامانه‌ی \lr{AlphaStar} بود که نشان داد ترکیب خودبازی و معماری توزیع‌شده می‌تواند به رتبه‌ی استاد بزرگ\LTRfootnote{Grandmaster}
   انسان برساند \cite{Vinyals2019AlphaStar}. 

در ۲۰۲۰ مفهوم نقش‌های در حال ظهور با \lr{ROMA} \cite{Wang2020ROMA} معرفی شد تا عامل‌ها بر اساس شباهت رفتاری به‌طور خودکار خوشه‌بندی و اشتراک دانش کنند؛ رویکردی که در نقشه‌های پرتراکم \lr{SMAC} برتری محسوسی نشان داد. پژوهش‌های متا در ۲۰۲۱، از مرور نظری زانگ و بشار \cite{Zhang2021Survey} تا 
محک\LTRfootnote{Benchmark}
 تطبیقی پاپوداکیس و همکاران
\cite{9583665}،
 شکاف‌های باقی‌مانده در تضمین همگرایی و مقیاس را فهرست کردند. 

آخرین موج مطالعات بر ناهمگونی و ایمنی تمرکز دارد. مرور جامع \cite{Yu2022Heterogeneous} نشان می‌دهد که تفاوت در قابلیت‌ها و اطلاعات عامل‌ها، مسائلی نظیر تخصیص اعتبار و تعادل را پیچیده‌تر می‌سازد و به الگوریتم‌های سازگار با نقش‌های پویا نیاز دارد.

به‌طور خلاصه، مسیر تاریخی \lr{MARL} از الگوهای مستقل دهه‌ی ۱۹۹۰ به سامانه‌های توزیع‌شده‌ی امروزی، همواره با سه دغدغه‌ی اصلی هدایت شده است: کنترل انفجار بُعدی توابع ارزش، مقابله با غیرایستایی ناشی از یادگیری هم‌زمان، و انتقال مؤثر تجربه میان عامل‌ها. علی‌رغم پیشرفت‌های شتابان، تضمین ایمنی سخت‌گیرانه در محیط‌های شکست‌پذیر، مدیریت نقش‌های پویا در تیم‌های ناهمگون و کاهش نیاز به داده‌ی شبیه‌سازی پرهزینه همچنان چالش‌های باز باقی می‌مانند؛ چالش‌هایی که در این پژوهش با رویکرد ترکیبی مدل‌مبنا، مقاوم و چندعاملی پیگیری می‌شوند.
