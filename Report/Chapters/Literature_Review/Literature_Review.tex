\chapter{پیشینه پژوهش}

\input{Chapters/Literature_Review/Inter_Orbital_Missions}
\input{Chapters/Literature_Review/Differential_Games}
\input{Chapters/Literature_Review/Reinforcement_Learning}
\input{Chapters/Literature_Review/Multi-agent}




\subsection{ماموریت‌های بین‌مداری}
\subsubsection{تعریف ماموریت‌های بین‌مداری}
اصول طراحی و بهینه‌سازی ماموریت‌ها و چالش‌های ارتباطی و کنترلی.
\subsubsection{مدل‌سازی مسیرهای بین‌مداری}
رویکردهای عددی برای بهینه‌سازی مسیر و استفاده از یادگیری ماشینی در برنامه‌ریزی مسیر.
\subsubsection{ایمنی در ماموریت‌های بین‌مداری}
تضمین پایداری مسیرها در حضور عدم قطعیت و مدیریت ریسک برخورد.

\subsection{بازی دیفرانسیلی}
\subsubsection{اصول بازی دیفرانسیلی}
تعریف بازی دیفرانسیلی، مفاهیم پایه و کاربردهای آن در تعاملات چندعاملی.
\subsubsection{بازی دیفرانسیلی با جمع صفر}
مدل‌سازی مسائل با جمع صفر و کاربردهای آن در مسائل دفاعی و نظارتی.
\subsubsection{تکنیک‌های حل بازی‌های دیفرانسیلی}
روش‌های تحلیلی و استفاده از الگوریتم‌های یادگیری تقویتی.

\subsection{یادگیری تقویتی}
\subsubsection{مفاهیم یادگیری تقویتی}
سیاست، پاداش، و به‌روزرسانی ارزش‌ها.
\subsubsection{الگوریتم‌های پیشرفته یادگیری تقویتی}
الگوریتم‌های Monte Carlo، Temporal-Difference و Deep Q-Network.
\subsubsection{ایمنی در یادگیری تقویتی}
یادگیری ایمن، محدودیت‌ها و تضمین‌ها در سیاست‌های یادگیری.

\subsection{یادگیری تقویتی چندعاملی}
\subsubsection{تعریف و اهمیت یادگیری تقویتی چندعاملی}
مفهوم همکاری و رقابت در محیط‌های چندعاملی و اهمیت ایمنی.
\subsubsection{بازی‌های چندعاملی در یادگیری تقویتی}
بازی‌های جمع صفر، تعادل نش و کاربردهای آن‌ها.
\subsubsection{چالش‌های یادگیری تقویتی چندعاملی}
مدیریت تعارضات، تضمین پایداری و مشکلات همگرایی.
\subsubsection{ایمنی در یادگیری تقویتی چندعاملی}
تکنیک‌های تضمین ایمنی و کاربرد ایمنی در تعاملات حساس.
\subsubsection{الگوریتم‌های یادگیری تقویتی چندعاملی}
الگوریتم‌های همکاری مانند MADDPG و یادگیری توزیع‌شده با تضمین ایمنی.
\subsubsection{کاربرد MARL در مسائل نظری}
حل مسائل بازی‌های جمع صفر و مدل‌سازی مسائل رقابتی و همکاری.
\subsubsection{کاربرد MARL در ماموریت‌های فضایی}
هماهنگی میان ماهواره‌ها، تخصیص منابع و حل مسائل ترکیبی در کاوش سیارات.

\section{یادگیری تقویتی چندعاملی}

\subsection{تعریف و اهمیت یادگیری تقویتی چندعاملی}
\subsubsection{تعریف یادگیری تقویتی چندعاملی}
% محتوای مربوط به تعریف MARL

\subsubsection{اهمیت یادگیری تقویتی چندعاملی}
% محتوای مربوط به اهمیت MARL

\subsection{بازی‌های چندعاملی در یادگیری تقویتی}
\subsubsection{بازی‌های جمع صفر}
% توضیح درباره بازی‌های جمع صفر

\subsubsection{تعادل نش و کاربردهای آن}
% توضیح درباره تعادل نش

\subsection{چالش‌های یادگیری تقویتی چندعاملی}
\subsubsection{مدیریت تعارضات}
% توضیح درباره مدیریت تعارضات

\subsubsection{تضمین پایداری}
% توضیح درباره تضمین پایداری

\subsubsection{مشکلات همگرایی}
% توضیح درباره مشکلات همگرایی

\subsection{ایمنی در یادگیری تقویتی چندعاملی}
\subsubsection{تکنیک‌های تضمین ایمنی}
% توضیح درباره تکنیک‌های ایمنی

\subsubsection{کاربرد ایمنی در تعاملات حساس}
% توضیح درباره کاربرد ایمنی

\subsection{الگوریتم‌های یادگیری تقویتی چندعاملی}
\subsubsection{الگوریتم‌های همکاری مانند MADDPG}
% توضیح درباره MADDPG و الگوریتم‌های همکاری

\subsubsection{یادگیری توزیع‌شده با تضمین ایمنی}
% توضیح درباره یادگیری توزیع‌شده

\subsection{کاربرد MARL در مسائل نظری}
\subsubsection{حل مسائل بازی‌های جمع صفر}
% توضیح درباره حل بازی‌های جمع صفر

\subsubsection{مدل‌سازی مسائل رقابتی و همکاری}
% توضیح درباره مدل‌سازی مسائل

\subsection{کاربرد MARL در ماموریت‌های فضایی}
\subsubsection{هماهنگی میان ماهواره‌ها}
% توضیح درباره هماهنگی ماهواره‌ها

\subsubsection{تخصیص منابع}
% توضیح درباره تخصیص منابع

\subsubsection{حل مسائل ترکیبی در کاوش سیارات}
% توضیح درباره حل مسائل ترکیبی


\section{کاربرد مولتی‌اِجنت در بازی‌ها}

در این بخش به بررسی کاربردهای مولتی‌اِجنت در حوزه بازی‌ها پرداخته و نشان می‌دهیم که الگوریتم پیشنهادی ما نه تنها بهینه بلکه ایمن و قابل اعتماد است.

\section{کاربرد چند عاملی در بازی‌ها}

در این بخش به بررسی کاربردهای یادگیری تقویتی چند عاملی در حوزه بازی‌ها پرداخته و نشان می‌دهیم که الگوریتم پیشنهادی ما نه تنها بهینه بلکه ایمن و قابل اعتماد است.

\subsection{تعریف بازی‌های چند عاملی}
\subsubsection{مفاهیم پایه در بازی‌های چند عاملی}
بازی‌های چند عاملی شامل محیط‌هایی هستند که در آن چندین عامل به صورت همزمان و مستقل به تعامل می‌پردازند. این تعاملات می‌تواند شامل همکاری، رقابت یا ترکیبی از هر دو باشد. در چنین محیط‌هایی، هر عامل با هدف خود به حداکثر رساندن پاداش یا دستیابی به اهداف مشخص، استراتژی‌های خود را توسعه می‌دهد.

\subsubsection{نمونه‌های بازی‌های چند عاملی}
از جمله نمونه‌های معروف بازی‌های چند عاملی می‌توان به بازی‌های استراتژیک مانند \lr{StarCraft}، بازی‌های ورزشی چند نفره و بازی‌های تخته‌ای مانند شطرنج چند عاملی اشاره کرد. این بازی‌ها به دلیل پیچیدگی‌های بالای تعاملات میان عوامل، محیط‌های مناسبی برای آزمایش و ارزیابی الگوریتم‌های یادگیری تقویتی چند عاملی فراهم می‌کنند.

\subsection{الگوریتم بهینه در بازی‌های چند عاملی}
\subsubsection{معرفی الگوریتم پیشنهادی}
الگوریتم پیشنهادی ما بر اساس ترکیبی از یادگیری عمیق و تکنیک‌های بهینه‌سازی چند عاملی طراحی شده است. این الگوریتم با استفاده از شبکه‌های عصبی عمیق، استراتژی‌های بهینه برای هر عامل را در محیط‌های پیچیده بازی‌های چند عاملی یاد می‌گیرد. علاوه بر این، با استفاده از مکانیزم‌های تعاملی، هماهنگی و همکاری میان عوامل بهبود می‌یابد.

\subsubsection{بهینه بودن الگوریتم}
الگوریتم ما با هدف کاهش زمان همگرایی و افزایش کارایی در محیط‌های دینامیک بهینه شده است. با استفاده از تکنیک‌های پیشرفته مانند یادگیری انتقالی و تنظیم خودکار نرخ یادگیری، الگوریتم قادر است به سرعت به تعادل‌های مطلوب برسد و عملکرد بهینه‌ای در بازی‌ها ارائه دهد.

\subsection{ایمنی و قابلیت اطمینان الگوریتم در بازی‌ها}
\subsubsection{تضمین ایمنی در تعاملات میان عوامل}
ایمنی در تعاملات چند عاملی به معنای جلوگیری از رفتارهای غیرمنتظره و تضمین هماهنگی میان عوامل است. در الگوریتم ما، از مکانیزم‌های نظارتی و محدودکننده استفاده شده است که اطمینان حاصل می‌کنند تعاملات میان عوامل منجر به نتیجه‌ای نامطلوب نمی‌شود. این شامل محدود کردن فضای عملیاتی و اعمال قیود بر سیاست‌های یادگیری هر عامل می‌باشد.

\subsubsection{قابلیت اطمینان و مقاومت در برابر خطاها}
الگوریتم پیشنهادی با هدف افزایش قابلیت اطمینان و مقاومت در برابر خطاها طراحی شده است. با استفاده از تکنیک‌های افزونگی و یادگیری توزیع‌شده، الگوریتم قادر است در صورت بروز خطا یا نقص در برخی از عوامل، به عملکرد مطلوب خود ادامه دهد. این ویژگی‌ها الگوریتم را برای استفاده در محیط‌های حساس و پویا مناسب می‌سازد.

\subsection{مطالعات موردی و نتایج تجربی}
\subsubsection{پیاده‌سازی در بازی‌های مشخص}
الگوریتم ما در بازی‌های مختلفی مانند بازی استراتژیک \lr{StarCraft} و بازی‌های ورزشی چند نفره پیاده‌سازی شده است. در هر یک از این بازی‌ها، عملکرد الگوریتم ما با توجه به معیارهای بهینه بودن و ایمنی ارزیابی شده است.

\subsubsection{تحلیل عملکرد و مقایسه با الگوریتم‌های دیگر}
نتایج تجربی نشان می‌دهد که الگوریتم پیشنهادی ما نسبت به الگوریتم‌های موجود در زمینه یادگیری تقویتی چند عاملی از نظر سرعت همگرایی و کارایی بهتری دارد. علاوه بر این، با استفاده از مکانیزم‌های تضمین ایمنی، رفتارهای ناخواسته و خطرناک در تعاملات میان عوامل به طور قابل توجهی کاهش یافته است.

\subsection{نتیجه‌گیری}
در این بخش، به بررسی و تحلیل نتایج به دست آمده از پیاده‌سازی الگوریتم پیشنهادی در بازی‌های چند عاملی پرداخته شد. مشاهده شد که الگوریتم ما توانسته است با ارائه راه‌حل‌های بهینه و ایمن، عملکرد بهتری نسبت به الگوریتم‌های موجود داشته باشد. این امر نشان‌دهنده قابلیت‌های بالای الگوریتم در مدیریت تعاملات پیچیده و تضمین ایمنی در محیط‌های چند عاملی است.

\subsection{پیشنهادات برای تحقیقات آینده}
با توجه به نتایج حاصل شده، پیشنهاد می‌شود که تحقیقات آینده بر روی بهبود بیشتر ایمنی و قابلیت اطمینان الگوریتم‌های چند عاملی متمرکز شود. همچنین، توسعه الگوریتم‌های سازگار با محیط‌های پویا و پیچیده‌تر و ارزیابی آن‌ها در بازی‌ها و محیط‌های واقعی‌تر از جمله مسیرهای پیشنهادی برای ادامه تحقیقات می‌باشد.

