% -------------------------------------------------------
%  Conclusion
% -------------------------------------------------------

\chapter{نتیجه‌گیری و پیشنهادها}
\label{chap:conclusion}

\noindent
در این پایان‌نامه، مسأله‌ی هدایتِ مقاومِ فضاپیماهای کم‌پیشران در دینامیکِ چندجسمیِ مدلِ \lr{CRTBP} زمین–ماه به‌صورت یک {بازی دیفرانسیلی مجموع‌صفر} میان عامل هدایت و عامل مزاحم صورت‌بندی شد و با الگوی {آموزش متمرکز–اجرای توزیع‌شده} دنبال گردید. چهار الگوریتم پیوسته‌ی \lr{DDPG}، \lr{TD3}، \lr{SAC} و \lr{PPO} به نسخه‌های چندعاملیِ مجموع‌صفر تعمیم داده شدند، اجزای بازیگر–منتقد و سازوکارهای پایداری آموزش تشریح گردید. ارزیابی گسترده زیر عدم‌قطعیت‌های واقع‌گرایانه شرایط اولیه‌ی تصادفی، اغتشاش عملگر، نویز حسگر، تأخیر زمانی و عدم‌تطابق مدل نشان داد نسخه‌های مجموع‌صفر به‌صورت پایدار از همتایان تک‌عاملی پیشی می‌گیرند؛ به‌ویژه \lr{MA-TD3} بهترین سازش میان دقت مسیر، مصرف سوخت و پایداری را فراهم کرد.

\section{جمع‌بندی دستاوردها}
\begin{itemize}
  \item ارائه‌ی صورت‌بندی بازی دیفرانسیلی مجموع‌صفر برای هدایت کم‌پیشران در \lr{CRTBP} با آموزش متمرکز و اجرای توزیع‌شده.
  \item تعمیم چهار الگوریتم پرکاربرد \lr{RL} به نسخه‌های چندعاملی مجموع‌صفر و تبیین دقیق معماری بازیگر–منتقد و پایدارسازی آموزش.
  \item طراحی حریفِ یادگیر برای تنوع‌بخشی نظام‌مند به عدم‌قطعیت‌ها و ارتقای تاب‌آوری سیاست در سناریوهای دشوار.
  \item پروتکل ارزیابی چندمعیاره با شاخص‌های دقت مسیر، پاداش 
  و پایداری، و نشان‌دادن برتری
   منسجم نسخه‌های مجموع‌صفر.
%  \item پیاده‌سازی سبک‌وزن و قابل‌اجرا به‌صورت بلادرنگ با کوانتیزاسیون \lr{INT8} با افت دقت ناچیز.
\end{itemize}

%\section*{محدودیت‌ها}
%\begin{itemize}
%  \item تحلیل در چارچوب \lr{CRTBP} انجام شد؛ تعمیم کامل به میدان‌های چندجسمیِ مبتنی بر اپمریس یا اثرات غیرمداری (تابش خورشیدی، سایه، محدودیت توان/حرارت) مستلزم توسعه‌ی مدل است.
%  \item سناریوهای عدم‌قطعیت عمدتاً به‌صورت مستقل آزموده شدند؛ ارزیابی هم‌زمانِ ترکیبات شدیدتر می‌تواند تصویر محافظه‌کارانه‌تری ارائه دهد.
%  \item حساسیت به طراحی و مقیاس‌بندی پاداش و تنظیمات \lr{RL}؛ نیاز به مطالعه‌ی نظام‌مند حساسیت و ابلیشن برای جداسازی عوامل اثرگذار.
%  \item هزینه‌ی آموزش و نمونه‌کارایی: بودجه‌ی محاسباتی بالا و نوسان عملکرد نسبت به بذرهای تصادفی می‌تواند بازتولید را دشوار کند.
%  \item تضمین‌های نظری محدود درباره‌ی ایمنی و بهینگی در حضور تأخیر و عدم‌تطابق مدل؛ نیاز به چارچوب‌های رسمی‌تر.
%\end{itemize}

\section{پیشنهادهایی برای کارهای آینده}
\begin{itemize}
	\item تعمیم چارچوب به مسئله \lr{$N$-body} و درنظرگرفتن اغتشاشات غیرگرانشی؛ استفاده از یادگیری مرحله‌ای (\lr{curriculum}) متناسب با پیچیدگی دینامیکی.
	\item بررسی \lr{Risk-Sensitive RL}، اعمال قیود ایمنی به‌صورت \lr{chance constraints} و به‌کارگیری \lr{Control Barrier Functions}
	 برای فراهم‌کردن تضمین.
	\item توسعه راهبردهای ترکیبی یادگیری تقویتی و کنترل مبتنی بر مدل (مانند \lr{MPC}/\lr{iLQR}) برای بهبود ایمنی و تفسیرپذیری.
	\item آموزش خصمانه مبتنی بر توزیع (جمعیت مزاحم‌ها) و طراحی \lr{curriculum/adversary shaping} برای پوشش بهتر نواحی عدم‌قطعیت.
	\item استقرار روی سامانه‌های تعبیه‌شده‌ی کم‌مصرف و مقایسه‌ی \lr{ONNX Runtime}، \lr{TVM} و \lr{TensorRT} در معماری‌های گوناگون؛ بهینه‌سازی \lr{latency/throughput} و سنجه‌ی \lr{energy–delay}.
	\item انجام تحلیل حساسیت نسبت به تابع پاداش، معماری، نویز حسگر و تأخیر؛ مستندسازی دقیق برای ارتقای بازتولیدپذیری.
\end{itemize}
       

\vspace{0.5em}
در مجموع، نتایج این پژوهش نشان داد که رویکرد بازی‌محور چندعاملی در یادگیری تقویتی می‌تواند هدایت تطبیقی و مقاوم را بدون اتکای شدید به مدل‌های دقیق فراهم کند و مسیر روشنی برای گذار به کاربردهای عملی و سناریوهای پیچیده‌تر می‌گشاید.



\subsection{محدودیت سنیاریوهای آزمون}

در این پژوهش، ارزیابی چارچوب پیشنهادی یادگیری تقویتی چندعاملی در چارچوب مسأله‌ی محدود سه‌جسمی، بر روی سناریوی انتقال کم‌تراست در حوالی نقطه‌ی لاگرانژ $L_1$ و نزدیک به مدار هدف در مجاورت $L_2$ متمرکز شده است. انتخاب این سناریو به دو دلیل اصلی انجام شده است:

\begin{itemize}
	\item این سناریو یکی از سناریوهای مرجع و رایج در ادبیات هدایت کم‌تراست در CRTBP محسوب می‌شود و امکان مقایسه‌ی مستقیم با روش‌های موجود را فراهم می‌کند؛
	\item تمرکز پژوهش حاضر بر \textbf{تبیین و ارزیابی چارچوب مقاوم مبتنی بر بازی دیفرانسیلی و یادگیری تقویتی چندعاملی} بوده است و نه طراحی جامع کلیه‌ی پروفایل‌های مأموریتی ممکن در محیط سه‌جسمی.
\end{itemize}

گسترش آزمون‌ها به نقاط شروع و پایان دیگر (برای مثال حوالی سایر نقاط لاگرانژ یا مدارهای هدف متفاوت)، علاوه بر تغییر شرایط اولیه، مستلزم حل یک مسأله‌ی مجزای طراحی مسیر و تعریف مجدد قیود مأموریتی و تابع پاداش است. از آن‌جا که این موارد خود به‌تنهایی می‌توانند موضوع یک پژوهش مستقل باشند، در این رساله به‌عنوان \textbf{کار آینده} در نظر گرفته شده‌اند و تمرکز بر روی یک سناریوی شاخص، امکان تحلیل عمیق‌تر رفتار الگوریتم‌های پیشنهادی را فراهم نموده است.

با وجود این محدودیت، در فصل~\ref{chap:results} نشان داده شد که چارچوب پیشنهادی در برابر طیفی از عدم‌قطعیت‌ها شامل تأخیر حسگر، نویز عملگر و عدم‌تطابق مدل، رفتار پایدار و مقاومی از خود بروز می‌دهد. این نتایج نشان می‌دهد که روش ارائه‌شده صرفاً به یک نقطه‌ی شروع و پایان خاص وابسته نیست و پایداری آن بیش از آن‌که تابع دقیق شرایط اولیه باشد، به ساختار بازی دیفرانسیلی و طراحی تابع پاداش مقاوم مرتبط است.
